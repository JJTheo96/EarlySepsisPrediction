{"cells":[{"cell_type":"markdown","metadata":{"id":"Nut3dwuDWjpR"},"source":["## Import Libs"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":355},"executionInfo":{"elapsed":1703,"status":"error","timestamp":1666878227647,"user":{"displayName":"Jinyi Jin","userId":"06348382445328590699"},"user_tz":-120},"id":"1wLMMgvIWHBx","outputId":"1a8adcee-30e1-468f-e0f0-d61330716f87"},"outputs":[],"source":["import os\n","import sys\n","import pickle\n","import pandas as pd\n","import numpy as np\n","from numpy import sort\n","from tqdm import tqdm\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from sklearn.feature_selection import SelectFromModel\n","from sklearn.metrics import classification_report, auc, precision_recall_curve, roc_curve, roc_auc_score\n","from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n","from plot_metric.functions import BinaryClassification\n","import matplotlib.pyplot as plt\n","import xgboost as xgb\n","from xgboost import XGBClassifier\n","from xgboost import plot_importance\n","from hyperopt import STATUS_OK, hp, fmin, tpe"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"YzuBhAXSW1Q6"},"outputs":[{"name":"stdout","output_type":"stream","text":["['Latin Modern Roman']\n"]}],"source":["# check the system font\n","import matplotlib.font_manager as font_manager\n","font_manager.findSystemFonts(fontpaths=None, fontext='ttf')\n","\n","# add the font wanted\n","font_dir = ['../../Latin-Modern-Roman/']\n","for font in font_manager.findSystemFonts(font_dir):\n","    font_manager.fontManager.addfont(font)\n","\n","# Set font family globally\n","plt.rcParams['font.family'] = 'Latin Modern Roman'\n","print(plt.rcParams['font.family'])\n","plt.rcParams.update({'font.size': 12})"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Training Helper Functions"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Hyper-params Tuning"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def BO_TPE(X_train, y_train, X_val, y_val):\n","    \"Hyperparameter optimization\"\n","    train = xgb.DMatrix(X_train, label=y_train)\n","    val = xgb.DMatrix(X_val, label=y_val)\n","    X_val_D = xgb.DMatrix(X_val)    #DMatrix is an internal data structure that is used by XGBoost, which is optimized for both memory efficiency and training speed.\n","\n","\n","    def objective(params):\n","        xgb_model = xgb.train(params, dtrain=train, num_boost_round=1000, evals=[(val, 'eval')],\n","                              verbose_eval=False, early_stopping_rounds=80)\n","        y_vd_pred = xgb_model.predict(X_val_D, ntree_limit=xgb_model.best_ntree_limit)\n","        y_val_class = [0 if i <= 0.5 else 1 for i in y_vd_pred]\n","\n","        acc = accuracy_score(y_val, y_val_class)\n","        loss = 1 - acc\n","\n","        return {'loss': loss, 'params': params, 'status': STATUS_OK}\n","\n","    max_depths = [3, 4]\n","    learning_rates = [0.01, 0.02, 0.04, 0.06, 0.08, 0.1, 0.15, 0.2]\n","    subsamples = [0.5, 0.6, 0.7, 0.8, 0.9]\n","    colsample_bytrees = [0.5, 0.6, 0.7, 0.8, 0.9]\n","    reg_alphas = [0.0, 0.005, 0.01, 0.05, 0.1]\n","    reg_lambdas = [0.8, 1, 1.5, 2, 4]\n","\n","    space = {\n","        'max_depth': hp.choice('max_depth', max_depths),\n","        'learning_rate': hp.choice('learning_rate', learning_rates),\n","        'subsample': hp.choice('subsample', subsamples),\n","        'colsample_bytree': hp.choice('colsample_bytree', colsample_bytrees),\n","        'reg_alpha': hp.choice('reg_alpha', reg_alphas),\n","        'reg_lambda': hp.choice('reg_lambda', reg_lambdas),\n","    }\n","\n","    best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=20)\n","\n","    best_param = {'max_depth': max_depths[(best['max_depth'])],\n","                  'learning_rate': learning_rates[(best['learning_rate'])],\n","                  'subsample': subsamples[(best['subsample'])],\n","                  'colsample_bytree': colsample_bytrees[(best['colsample_bytree'])],\n","                  'reg_alpha': reg_alphas[(best['reg_alpha'])],\n","                  'reg_lambda': reg_lambdas[(best['reg_lambda'])]\n","                  }\n","\n","    return best_param"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Train Model"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["def train_model(k, X_train, y_train, X_val, y_val, save_model_dir, fig_name_val, fig_name_fi, features):\n","    print('*************************************************************')\n","    print('{}th training ..............'.format(k + 1))\n","    print('Hyperparameters optimization')\n","    best_param = BO_TPE(X_train, y_train, X_val, y_val)\n","    print('Best Params: ', best_param)\n","    xgb_model = xgb.XGBClassifier(max_depth = best_param['max_depth'],\n","                                  eta = best_param['learning_rate'],\n","                                  n_estimators = 1000,\n","                                  subsample = best_param['subsample'],\n","                                  colsample_bytree = best_param['colsample_bytree'],\n","                                  reg_alpha = best_param['reg_alpha'],\n","                                  reg_lambda = best_param['reg_lambda'],\n","                                  objective = \"binary:logistic\"\n","                                  )\n","\n","    xgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric='error',\n","                  early_stopping_rounds=80, verbose=False)\n","\n","    # print training performance\n","    y_tr_pred = (xgb_model.predict_proba(X_train, ntree_limit=xgb_model.best_ntree_limit))[:, 1]\n","    train_auc = roc_auc_score(y_train, y_tr_pred)\n","    print('training dataset AUC: ' + str(train_auc))\n","    y_tr_class = [0 if i <= 0.5 else 1 for i in y_tr_pred]\n","    acc = accuracy_score(y_train, y_tr_class)\n","    print('training dataset acc: ' + str(acc))\n","\n","    #print validation performance \n","    y_vd_pred = (xgb_model.predict_proba(X_val, ntree_limit=xgb_model.best_ntree_limit))[:, 1]\n","    valid_auc = roc_auc_score(y_val, y_vd_pred)\n","    print('validation dataset AUROC: ' + str(valid_auc))\n","    precision_, recall_, thresholds_ = precision_recall_curve(y_val, y_vd_pred)\n","    auprc_ = auc(recall_, precision_)\n","    print('validation dataset AUPRC: ' + str(auprc_))\n","    y_val_class = [0 if i <= 0.5 else 1 for i in y_vd_pred]\n","    valid_acc = accuracy_score(y_val, y_val_class)\n","    print('validation dataset acc: ' + str(valid_acc))\n","    f1_ = f1_score(y_val,y_val_class)\n","    print('validation dataset F1: ' + str(f1_))\n","    fpr_, tpr_, thresholds_ = roc_curve(y_val, y_vd_pred)\n","    print('************************************************************')\n","\n","    # save the model\n","    save_model_path = save_model_dir + 'model{}.mdl'.format(k + 1)\n","    # xgb_model.get_booster().save_model(fname=save_model_path)\n","\n","    # Plot ROC,PRC and confusion matrix\n","    bc = BinaryClassification(y_val,y_vd_pred, labels=['Non-sepsis', 'Sepsis'])\n","    # plt.figure(figsize=(11.69,8.27))\n","    plt.figure(figsize=(10,10))\n","    plt.subplot2grid(shape=(2,4), loc=(0,0), colspan=2)\n","    bc.plot_roc_curve()\n","    plt.subplot2grid((2,4), (0,2), colspan=2)\n","    bc.plot_precision_recall_curve()\n","    plt.subplot2grid((2,4), (1,0), colspan=2)\n","    bc.plot_confusion_matrix()\n","    plt.subplot2grid((2,4), (1,2), colspan=2)\n","    bc.plot_confusion_matrix(normalize=True)\n","    plt.savefig('./figs_temp/{}_{}.pdf'.format(fig_name_val, k+1))\n","    plt.clf()\n","\n","    # < ----- uncomment below for feature selection process\n","\n","    # # Explore feature importance \n","    # print('---Feature Importance---')\n","    # # plot feature importance\n","    # plot_importance(xgb_model)\n","\n","    # #plot graph of feature importances for better visualization\n","    # feat_importances = pd.Series(xgb_model.feature_importances_, index=features)\n","    # feat_importances.nlargest(len(features)).plot(kind='barh')\n","    # plt.savefig('./figs/{}_{}.pdf'.format(fig_name_fi, k+1))\n","    # plt.clf()\n","\n","\n","    # # Fit model using each importance as a threshold \n","    # thresholds = sort(xgb_model.feature_importances_)\n","    # # feature and performance \n","    # for thresh in thresholds:\n","    #     # select features using threshold\n","    #     selection = SelectFromModel(xgb_model, threshold=thresh, prefit=True)\n","    #     select_X_train = selection.transform(X_train)\n","    #     # train model\n","    #     selection_model = XGBClassifier()\n","    #     selection_model.fit(select_X_train, y_train)\n","    #     # eval model\n","    #     select_X_test = selection.transform(X_val)\n","    #     predictions = selection_model.predict(select_X_test)\n","    #     accuracy = accuracy_score(y_val, predictions)\n","    #     print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Data Process"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def gather_dfs(data_path, patient_ids):\n","\n","    gathered_df = pd.DataFrame([])\n","\n","    for p in tqdm(patient_ids):\n","        # read in patient data\n","        p = str(np.char.replace(p,'psv','csv'))\n","        df = pd.read_csv(data_path + p, sep = \",\")\n","        if 'time' in df.columns: df = df.drop(['time'],axis=1)   # drop column time if exists\n","        gathered_df = pd.concat([gathered_df, df], ignore_index=True)\n","    \n","    return gathered_df"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def expand_sepsis_label(df):\n","\n","    number_nonsepsis_label = df.groupby('sepsis')['sepsis'].count()[0]\n","    print('Number of Non-sepsis label:', number_nonsepsis_label)\n","    number_sepsis_label = df.groupby('sepsis')['sepsis'].count()[1]\n","    print('Number of Sepsis label:', number_sepsis_label)\n","\n","    expand_times = round((number_nonsepsis_label-number_sepsis_label)/number_sepsis_label)\n","\n","    df_is_sepsis = df['sepsis']==1\n","    df_to_expand = df[df_is_sepsis]\n","    df_expanded = df.append([df_to_expand]*expand_times, ignore_index = True)\n","\n","    number_nonsepsis_label = df_expanded.groupby('sepsis')['sepsis'].count()[0]\n","    print('After Expansion:\\nNumber of Non-sepsis label:', number_nonsepsis_label)\n","    number_sepsis_label = df_expanded.groupby('sepsis')['sepsis'].count()[1]\n","    print('Number of Sepsis label:', number_sepsis_label)\n","\n","    return df_expanded"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Train Model"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["!mkdir -p ./trained_models/BDWOFS/\n","!mkdir -p ./trained_models/BDWFS/\n","!mkdir -p ./trained_models/EDWOFS/\n","!mkdir -p ./trained_models/EDWFS/"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Baseline Data without Feature Selection"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["X_feature_baseline = ['HR', 'SaO2', 'Temp', 'SBP', 'MAP', 'DBP', 'RR', 'BaseExcess', 'HCO3',\n","                      'PH', 'BUN', 'Calcium', 'Chloride', 'Creatinine', 'Glucose', 'Lactic',\n","                      'Magnesium', 'Potassium', 'PTT', 'WBC', 'Platelet', 'age', 'gender']\n","\n","y_feature = ['sepsis']"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["---Fold1/5---\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4/4 [00:00<00:00, 244.99it/s]\n","100%|██████████| 8/8 [00:00<00:00, 115.13it/s]\n","100%|██████████| 2/2 [00:00<00:00, 89.21it/s]\n","100%|██████████| 4/4 [00:00<00:00, 143.02it/s]"]},{"name":"stdout","output_type":"stream","text":["Number of Non-sepsis label: 278\n","Number of Sepsis label: 27\n","After Expansion:\n","Number of Non-sepsis label: 278\n","Number of Sepsis label: 270\n","Number of Non-sepsis label: 606\n","Number of Sepsis label: 53\n","After Expansion:\n","Number of Non-sepsis label: 606\n","Number of Sepsis label: 583\n","---Start training process---\n","*************************************************************\n","1th training ..............\n","Hyperparameters optimization\n","  0%|          | 0/20 [00:00<?, ?trial/s, best loss=?]"]},{"name":"stderr","output_type":"stream","text":["\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 10%|█         | 2/20 [00:00<00:01, 11.16trial/s, best loss: 0.4238856181665265]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 20%|██        | 4/20 [00:00<00:01, 11.46trial/s, best loss: 0.4238856181665265]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 30%|███       | 6/20 [00:00<00:01, 11.17trial/s, best loss: 0.4238856181665265]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 40%|████      | 8/20 [00:00<00:01, 11.13trial/s, best loss: 0.4238856181665265]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 50%|█████     | 10/20 [00:00<00:01,  9.28trial/s, best loss: 0.4238856181665265]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 60%|██████    | 12/20 [00:01<00:00,  9.72trial/s, best loss: 0.4238856181665265]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 70%|███████   | 14/20 [00:01<00:00, 10.27trial/s, best loss: 0.4238856181665265]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 80%|████████  | 16/20 [00:01<00:00, 10.38trial/s, best loss: 0.4238856181665265]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":["100%|██████████| 20/20 [00:01<00:00, 10.45trial/s, best loss: 0.4238856181665265]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n","  UserWarning,\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n","  UserWarning,\n"]},{"name":"stdout","output_type":"stream","text":["\n","Best Params:  {'max_depth': 4, 'learning_rate': 0.02, 'subsample': 0.5, 'colsample_bytree': 0.5, 'reg_alpha': 0.005, 'reg_lambda': 2}\n"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n"]},{"name":"stdout","output_type":"stream","text":["training dataset AUC: 0.9672262190247802\n","training dataset acc: 0.9562043795620438\n","validation dataset AUROC: 0.43467837349772714\n","validation dataset AUPRC: 0.5532075811008788\n","validation dataset acc: 0.5761143818334735\n","validation dataset F1: 0.282051282051282\n","************************************************************\n","---Fold2/5---\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4/4 [00:00<00:00, 240.04it/s]\n","100%|██████████| 8/8 [00:00<00:00, 252.95it/s]\n","100%|██████████| 2/2 [00:00<00:00, 205.57it/s]\n","100%|██████████| 4/4 [00:00<00:00, 179.00it/s]"]},{"name":"stdout","output_type":"stream","text":["Number of Non-sepsis label: 251\n","Number of Sepsis label: 24\n","After Expansion:\n","Number of Non-sepsis label: 251\n","Number of Sepsis label: 240\n","Number of Non-sepsis label: 505\n","Number of Sepsis label: 53\n","After Expansion:\n","Number of Non-sepsis label: 505\n","Number of Sepsis label: 530\n","---Start training process---\n","*************************************************************\n","2th training ..............\n","Hyperparameters optimization\n","  0%|          | 0/20 [00:00<?, ?trial/s, best loss=?]"]},{"name":"stderr","output_type":"stream","text":["\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 10%|█         | 2/20 [00:00<00:02,  8.84trial/s, best loss: 0.43768115942028984]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 20%|██        | 4/20 [00:00<00:01, 10.42trial/s, best loss: 0.43671497584541064]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 30%|███       | 6/20 [00:00<00:01, 10.49trial/s, best loss: 0.43671497584541064]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 40%|████      | 8/20 [00:00<00:01, 10.58trial/s, best loss: 0.43671497584541064]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 50%|█████     | 10/20 [00:00<00:00, 11.22trial/s, best loss: 0.43671497584541064]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 60%|██████    | 12/20 [00:01<00:00,  9.79trial/s, best loss: 0.42995169082125606]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 80%|████████  | 16/20 [00:01<00:00, 10.64trial/s, best loss: 0.42995169082125606]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 90%|█████████ | 18/20 [00:01<00:00, 11.07trial/s, best loss: 0.42995169082125606]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":["100%|██████████| 20/20 [00:01<00:00, 10.67trial/s, best loss: 0.42995169082125606]\n","Best Params:  {'max_depth': 4, 'learning_rate': 0.01, 'subsample': 0.7, 'colsample_bytree': 0.6, 'reg_alpha': 0.0, 'reg_lambda': 1}\n"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n","  UserWarning,\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n","  UserWarning,\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n"]},{"name":"stdout","output_type":"stream","text":["training dataset AUC: 0.995683930942895\n","training dataset acc: 0.9714867617107943\n","validation dataset AUROC: 0.6179712310853727\n","validation dataset AUPRC: 0.6727167510461588\n","validation dataset acc: 0.5739130434782609\n","validation dataset F1: 0.3328290468986384\n","************************************************************\n","---Fold3/5---\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4/4 [00:00<00:00, 146.13it/s]\n","100%|██████████| 8/8 [00:00<00:00, 176.51it/s]\n","100%|██████████| 2/2 [00:00<00:00, 231.65it/s]\n","100%|██████████| 4/4 [00:00<00:00, 208.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Number of Non-sepsis label: 376\n","Number of Sepsis label: 26\n","After Expansion:\n","Number of Non-sepsis label: 376\n","Number of Sepsis label: 364\n","Number of Non-sepsis label: 407\n","Number of Sepsis label: 54\n","After Expansion:\n","Number of Non-sepsis label: 407\n","Number of Sepsis label: 432\n","---Start training process---\n","*************************************************************\n","3th training ..............\n","Hyperparameters optimization\n","  0%|          | 0/20 [00:00<?, ?trial/s, best loss=?]"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":[" 15%|█▌        | 3/20 [00:00<00:01,  8.80trial/s, best loss: 0.4135876042908224]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 30%|███       | 6/20 [00:00<00:01, 10.14trial/s, best loss: 0.37425506555423127]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 40%|████      | 8/20 [00:00<00:01, 10.69trial/s, best loss: 0.37425506555423127]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 60%|██████    | 12/20 [00:01<00:00, 10.43trial/s, best loss: 0.36710369487485106]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 70%|███████   | 14/20 [00:01<00:00, 10.39trial/s, best loss: 0.36710369487485106]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 90%|█████████ | 18/20 [00:01<00:00, 10.68trial/s, best loss: 0.36710369487485106]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":["100%|██████████| 20/20 [00:02<00:00,  9.78trial/s, best loss: 0.36710369487485106]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n","  UserWarning,\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n","  UserWarning,\n"]},{"name":"stdout","output_type":"stream","text":["\n","Best Params:  {'max_depth': 3, 'learning_rate': 0.2, 'subsample': 0.5, 'colsample_bytree': 0.5, 'reg_alpha': 0.1, 'reg_lambda': 0.8}\n","training dataset AUC: 0.8592471358428806\n","training dataset acc: 0.7878378378378378\n","validation dataset AUROC: 0.6127718627718628\n","validation dataset AUPRC: 0.7317973125394353\n","validation dataset acc: 0.6328963051251489\n","validation dataset F1: 0.6577777777777778\n","************************************************************\n"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n"]},{"name":"stdout","output_type":"stream","text":["---Fold4/5---\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4/4 [00:00<00:00, 136.12it/s]\n","100%|██████████| 8/8 [00:00<00:00, 128.67it/s]\n","100%|██████████| 2/2 [00:00<00:00, 102.87it/s]\n","100%|██████████| 4/4 [00:00<00:00, 154.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Number of Non-sepsis label: 415\n","Number of Sepsis label: 26\n","After Expansion:\n","Number of Non-sepsis label: 415\n","Number of Sepsis label: 416\n","Number of Non-sepsis label: 870\n","Number of Sepsis label: 53\n","After Expansion:\n","Number of Non-sepsis label: 870\n","Number of Sepsis label: 848\n","---Start training process---\n","*************************************************************\n","4th training ..............\n","Hyperparameters optimization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["  0%|          | 0/20 [00:00<?, ?trial/s, best loss=?]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 10%|█         | 2/20 [00:00<00:01,  9.86trial/s, best loss: 0.43888242142025613]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 20%|██        | 4/20 [00:00<00:01, 10.44trial/s, best loss: 0.3352735739231665] "]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 30%|███       | 6/20 [00:00<00:01, 10.89trial/s, best loss: 0.3352735739231665]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 40%|████      | 8/20 [00:00<00:01, 10.54trial/s, best loss: 0.3352735739231665]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 50%|█████     | 10/20 [00:00<00:00, 10.30trial/s, best loss: 0.3352735739231665]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 60%|██████    | 12/20 [00:01<00:00, 10.17trial/s, best loss: 0.3352735739231665]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 70%|███████   | 14/20 [00:01<00:00, 10.75trial/s, best loss: 0.3352735739231665]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 80%|████████  | 16/20 [00:01<00:00, 11.05trial/s, best loss: 0.3352735739231665]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 90%|█████████ | 18/20 [00:01<00:00, 11.44trial/s, best loss: 0.3352735739231665]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":["100%|██████████| 20/20 [00:01<00:00, 10.86trial/s, best loss: 0.3352735739231665]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n","  UserWarning,\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n","  UserWarning,\n"]},{"name":"stdout","output_type":"stream","text":["\n","Best Params:  {'max_depth': 3, 'learning_rate': 0.01, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.01, 'reg_lambda': 4}\n"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n"]},{"name":"stdout","output_type":"stream","text":["training dataset AUC: 0.9744207599629287\n","training dataset acc: 0.941034897713598\n","validation dataset AUROC: 0.6743005855562785\n","validation dataset AUPRC: 0.6436651580041455\n","validation dataset acc: 0.6647264260768335\n","validation dataset F1: 0.5609756097560975\n","************************************************************\n","---Fold5/5---\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4/4 [00:00<00:00, 211.06it/s]\n","100%|██████████| 8/8 [00:00<00:00, 258.36it/s]\n","100%|██████████| 2/2 [00:00<00:00, 171.32it/s]\n","100%|██████████| 4/4 [00:00<00:00, 225.11it/s]"]},{"name":"stdout","output_type":"stream","text":["Number of Non-sepsis label: 230\n","Number of Sepsis label: 25\n","After Expansion:\n","Number of Non-sepsis label: 230\n","Number of Sepsis label: 225\n","Number of Non-sepsis label: 656\n","Number of Sepsis label: 53\n","After Expansion:\n","Number of Non-sepsis label: 656\n","Number of Sepsis label: 636\n","---Start training process---\n","*************************************************************\n","5th training ..............\n","Hyperparameters optimization\n","  0%|          | 0/20 [00:00<?, ?trial/s, best loss=?]"]},{"name":"stderr","output_type":"stream","text":["\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 20%|██        | 4/20 [00:00<00:01, 14.25trial/s, best loss: 0.47987616099071206]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 30%|███       | 6/20 [00:00<00:01, 10.24trial/s, best loss: 0.47987616099071206]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 40%|████      | 8/20 [00:00<00:01, 11.51trial/s, best loss: 0.47987616099071206]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 50%|█████     | 10/20 [00:00<00:00, 12.40trial/s, best loss: 0.47987616099071206]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 60%|██████    | 12/20 [00:00<00:00, 13.14trial/s, best loss: 0.47987616099071206]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 70%|███████   | 14/20 [00:01<00:00, 13.53trial/s, best loss: 0.47987616099071206]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 80%|████████  | 16/20 [00:01<00:00, 13.98trial/s, best loss: 0.47987616099071206]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 90%|█████████ | 18/20 [00:01<00:00, 14.02trial/s, best loss: 0.47987616099071206]"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","\n"]},{"name":"stdout","output_type":"stream","text":["100%|██████████| 20/20 [00:01<00:00, 13.22trial/s, best loss: 0.47987616099071206]\n","Best Params:  {'max_depth': 3, 'learning_rate': 0.08, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 4}\n"]},{"name":"stderr","output_type":"stream","text":["/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n","  UserWarning,\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n","  UserWarning,\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n","/Users/jinyijin/.conda/envs/DL_Environment/lib/python3.7/site-packages/xgboost/core.py:93: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n","  UserWarning\n"]},{"name":"stdout","output_type":"stream","text":["training dataset AUC: 0.9983478260869566\n","training dataset acc: 0.9758241758241758\n","validation dataset AUROC: 0.48930050621260923\n","validation dataset AUPRC: 0.5958932374185746\n","validation dataset acc: 0.5386996904024768\n","validation dataset F1: 0.43346007604562736\n","************************************************************\n"]},{"data":{"text/plain":["<Figure size 720x720 with 0 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["<Figure size 720x720 with 0 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["<Figure size 720x720 with 0 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["<Figure size 720x720 with 0 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["<Figure size 720x720 with 0 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["#load data from Cinc2019\n","data_path_c = \"../../datasets/Cinc2019/baseline_all/\"  \n","train_nonsepsis_c = np.load('../data/data_Cinc2019/train_nonsepsis.npy')\n","train_sepsis_c = np.load('../data/data_Cinc2019/train_sepsis.npy')\n","\n","# load data from MIMIC-III\n","data_path_m = \"../../datasets/MIMICIII/adults/baseline_all/\"  \n","train_nonsepsis_m = np.load('../data/data_mimiciii/train_nonsepsis.npy')\n","train_sepsis_m = np.load('../data/data_mimiciii/train_sepsis.npy')\n","\n","# 5-fold cross validation was implemented and five XGBoost models were produced\n","sss = StratifiedShuffleSplit(n_splits=5, test_size = 3/17, random_state=np.random.seed(12306)) # val/train = 0.15/0.7\n","for (k, (train0_index, val0_index)), (k, (train1_index, val1_index)), (k, (train2_index, val2_index)), (k, (train3_index, val3_index))\\\n","     in zip(enumerate(sss.split(train_nonsepsis_c, np.zeros(train_nonsepsis_c.shape))), enumerate(sss.split(train_sepsis_c, np.zeros(train_sepsis_c.shape))), enumerate(sss.split(train_nonsepsis_m, np.zeros(train_nonsepsis_m.shape))), enumerate(sss.split(train_sepsis_m, np.zeros(train_sepsis_m.shape)))):\n","\n","    print('---Fold{}/5---'.format(k+1))\n","\n","    # read data from Cinc2019\n","    train_set_c = np.append((train_nonsepsis_c[train0_index])[:2], (train_sepsis_c[train1_index])[:2])\n","    val_set_c = np.append((train_nonsepsis_c[val0_index])[:4], (train_sepsis_c[val1_index][:4]))\n","#     train_set_c = np.append((train_nonsepsis_c[train0_index])[:2052], (train_sepsis_c[train1_index])[:2052])\n","#     val_set_c = np.append((train_nonsepsis_c[val0_index])[:440], (train_sepsis_c[val1_index][:440]))\n","    train_baseline_c = gather_dfs('../../datasets/Cinc2019/baseline_all/',train_set_c)\n","    val_baseline_c = gather_dfs('../../datasets/Cinc2019/baseline_all/',val_set_c)\n","\n","    # read data from MIMIC-III \n","    train_set_m = np.append((train_nonsepsis_m[train2_index][:1]), (train_sepsis_m[train3_index])[:1])\n","    val_set_m = np.append((train_nonsepsis_m[val2_index])[:2], (train_sepsis_m[val3_index])[:2])\n","#     train_set_m = np.append((train_nonsepsis_m[train2_index][:1320]), (train_sepsis_m[train3_index])[:1320])\n","#     val_set_m = np.append((train_nonsepsis_m[val2_index])[:283], (train_sepsis_m[val3_index])[:283])\n","    train_baseline_m = gather_dfs('../../datasets/MIMICIII/adults/baseline_all/',train_set_m)\n","    val_baseline_m = gather_dfs('../../datasets/MIMICIII/adults/baseline_all/',val_set_m)\n","\n","    # combine two datasets\n","    train_baseline_both = pd.concat([train_baseline_c,train_baseline_m], ignore_index=True)\n","    train_baseline = expand_sepsis_label(train_baseline_both) #balance sepsis and non-sepsis labels\n","    val_baseline_both = pd.concat([val_baseline_c,val_baseline_m], ignore_index=True)\n","    val_baseline = expand_sepsis_label(val_baseline_both) #balance sepsis and non-sepsis labels\n","\n","    x_train= train_baseline[X_feature_baseline]\n","    y_train = train_baseline[y_feature]\n","\n","    x_val = val_baseline[X_feature_baseline]\n","    y_val = val_baseline[y_feature]\n","\n","\n","    print('---Start training process---')\n","    train_model(k, x_train, y_train, x_val, y_val, \n","                save_model_dir = './trained_models/BDWOFS/',\n","                fig_name_val = 'val_wo_fs_baseline',\n","                fig_name_fi = 'feature_importance_baseline',\n","                features = X_feature_baseline)   #change here"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["ACC:0.6575627855807575|F1:0.6580375529299552|AUROC:0.7168965795294563|AUPRC:0.6990500431431828"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Baseline Data with Feature Engineering"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["From the results from above, with the increase of the feature numbers , accuracy starts to decreases when only 10 most important features are used. As a results, the most important 10 features, along with other 5 vital signs will be selected as the final 15 features."]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["X_feature_baseline_fs = ['Magnesium', 'HCO3', 'MAP', 'Chloride', 'SaO2', 'Potassium', 'BaseExcess', 'Glucose', 'PH', 'gender',\n","                        'RR', 'SBP', 'Temp', 'DBP', 'HR']\n","\n","y_feature = ['sepsis']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#load data from Cinc2019\n","data_path_c = \"../../datasets/Cinc2019/baseline_all/\"  \n","train_nonsepsis_c = np.load('../data/data_Cinc2019/train_nonsepsis.npy')\n","train_sepsis_c = np.load('../data/data_Cinc2019/train_sepsis.npy')\n","\n","# load data from MIMIC-III\n","data_path_m = \"../../datasets/MIMICIII/adults/baseline_all/\"  \n","train_nonsepsis_m = np.load('../data/data_mimiciii/train_nonsepsis.npy')\n","train_sepsis_m = np.load('../data/data_mimiciii/train_sepsis.npy')\n","\n","# 5-fold cross validation was implemented and five XGBoost models were produced\n","sss = StratifiedShuffleSplit(n_splits=5, test_size = 3/17, random_state=np.random.seed(12306)) # val/train = 0.15/0.7\n","for (k, (train0_index, val0_index)), (k, (train1_index, val1_index)), (k, (train2_index, val2_index)), (k, (train3_index, val3_index))\\\n","     in zip(enumerate(sss.split(train_nonsepsis_c, np.zeros(train_nonsepsis_c.shape))), enumerate(sss.split(train_sepsis_c, np.zeros(train_sepsis_c.shape))), enumerate(sss.split(train_nonsepsis_m, np.zeros(train_nonsepsis_m.shape))), enumerate(sss.split(train_sepsis_m, np.zeros(train_sepsis_m.shape)))):\n","\n","    print('---Fold{}/5---'.format(k+1))\n","\n","    # read data from Cinc2019\n","    train_set_c = np.append((train_nonsepsis_c[train0_index])[:2052], (train_sepsis_c[train1_index])[:2052])\n","    val_set_c = np.append((train_nonsepsis_c[val0_index])[:440], (train_sepsis_c[val1_index][:440]))\n","    train_baseline_c = gather_dfs('../../datasets/Cinc2019/baseline_all/',train_set_c)\n","    val_baseline_c = gather_dfs('../../datasets/Cinc2019/baseline_all/',val_set_c)\n","\n","    # read data from MIMIC-III \n","    train_set_m = np.append((train_nonsepsis_m[train2_index][:1320]), (train_sepsis_m[train3_index])[:1320])\n","    val_set_m = np.append((train_nonsepsis_m[val2_index])[:283], (train_sepsis_m[val3_index])[:283])\n","    train_baseline_m = gather_dfs('../../datasets/MIMICIII/adults/baseline_all/',train_set_m)\n","    val_baseline_m = gather_dfs('../../datasets/MIMICIII/adults/baseline_all/',val_set_m)\n","\n","    # combine two datasets\n","    train_baseline_both = pd.concat([train_baseline_c,train_baseline_m], ignore_index=True)\n","    train_baseline = expand_sepsis_label(train_baseline_both) #balance sepsis and non-sepsis labels\n","    val_baseline_both = pd.concat([val_baseline_c,val_baseline_m], ignore_index=True)\n","    val_baseline = expand_sepsis_label(val_baseline_both) #balance sepsis and non-sepsis labels\n","\n","    x_train= train_baseline[X_feature_baseline_fs]\n","    y_train = train_baseline[y_feature]\n","\n","    x_val = val_baseline[X_feature_baseline_fs]\n","    y_val = val_baseline[y_feature]\n","\n","\n","    print('---Start training process---')\n","    train_model(k, x_train, y_train, x_val, y_val, \n","                save_model_dir = './trained_models/BDWFS/',\n","                fig_name_val = 'val_w_fs_baseline',\n","                fig_name_fi = 'feature_importance_baseline',\n","                features = X_feature_baseline_fs)   #change here"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["ACC:0.6431193398244552|F1:0.639355669543864|AUROC:0.7024686209913262|AUPRC:0.6827815104252541"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Engineered Data without Feature Engineering"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["X_feature_engineered = ['HR', 'SaO2', 'Temp', 'SBP', 'MAP', 'DBP', 'RR', 'BaseExcess', 'HCO3',\n","       'PH', 'BUN', 'Calcium', 'Chloride', 'Creatinine', 'Glucose', 'Lactic',\n","       'Magnesium', 'Potassium', 'PTT', 'WBC', 'Platelet', 'age', 'gender',\n","       'HR_dev_1', 'HR_dev_2', 'HR_dev_3', 'RR_dev_1',\n","       'RR_dev_2', 'RR_dev_3', 'Temp_dev_1', 'Temp_dev_2', 'Temp_dev_3',\n","       'Bradycardia', 'Tachycardia', 'Hypothermia', 'Fever', 'Hyperpyrexia']\n","\n","y_feature = ['sepsis']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#load data from Cinc2019\n","data_path_c = \"../../datasets/Cinc2019/engineered_all/\"  \n","train_nonsepsis_c = np.load('../data/data_Cinc2019/train_nonsepsis.npy')\n","train_sepsis_c = np.load('../data/data_Cinc2019/train_sepsis.npy')\n","\n","# load data from MIMIC-III\n","data_path_m = \"../../datasets/MIMICIII/adults/engineered_all/\"  \n","train_nonsepsis_m = np.load('../data/data_mimiciii/train_nonsepsis.npy')\n","train_sepsis_m = np.load('../data/data_mimiciii/train_sepsis.npy')\n","\n","# 5-fold cross validation was implemented and five XGBoost models were produced\n","sss = StratifiedShuffleSplit(n_splits=5, test_size = 3/17, random_state=np.random.seed(12306)) # val/train = 0.15/0.7\n","for (k, (train0_index, val0_index)), (k, (train1_index, val1_index)), (k, (train2_index, val2_index)), (k, (train3_index, val3_index))\\\n","     in zip(enumerate(sss.split(train_nonsepsis_c, np.zeros(train_nonsepsis_c.shape))), enumerate(sss.split(train_sepsis_c, np.zeros(train_sepsis_c.shape))), enumerate(sss.split(train_nonsepsis_m, np.zeros(train_nonsepsis_m.shape))), enumerate(sss.split(train_sepsis_m, np.zeros(train_sepsis_m.shape)))):\n","\n","    print('---Fold{}/5---'.format(k+1))\n","\n","    # read data from Cinc2019\n","    train_set_c = np.append((train_nonsepsis_c[train0_index])[:2052], (train_sepsis_c[train1_index])[:2052])\n","    val_set_c = np.append((train_nonsepsis_c[val0_index])[:440], (train_sepsis_c[val1_index][:440]))\n","    train_engineered_c = gather_dfs('../../datasets/Cinc2019/engineered_all/',train_set_c)\n","    val_engineered_c = gather_dfs('../../datasets/Cinc2019/engineered_all/',val_set_c)\n","\n","    # read data from MIMIC-III \n","    train_set_m = np.append((train_nonsepsis_m[train2_index][:1320]), (train_sepsis_m[train3_index])[:1320])\n","    val_set_m = np.append((train_nonsepsis_m[val2_index])[:283], (train_sepsis_m[val3_index])[:283])\n","    train_engineered_m = gather_dfs('../../datasets/MIMICIII/adults/engineered_all/',train_set_m)\n","    val_engineered_m = gather_dfs('../../datasets/MIMICIII/adults/engineered_all/',val_set_m)\n","\n","    # combine two datasets\n","    train_engineered_both = pd.concat([train_engineered_c,train_engineered_m], ignore_index=True)\n","    train_engineered = expand_sepsis_label(train_engineered_both) #balance sepsis and non-sepsis labels\n","    val_engineered_both = pd.concat([val_engineered_c,val_engineered_m], ignore_index=True)\n","    val_engineered = expand_sepsis_label(val_engineered_both) #balance sepsis and non-sepsis labels\n","\n","    x_train= train_engineered[X_feature_engineered]\n","    y_train = train_engineered[y_feature]\n","\n","    x_val = val_engineered[X_feature_engineered]\n","    y_val = val_engineered[y_feature]\n","\n","\n","    print('---Start training process---')\n","    train_model(k, x_train, y_train, x_val, y_val, \n","                save_model_dir = './trained_models/EDWOFS/',\n","                fig_name_val = 'val_wo_fs_engineered',\n","                fig_name_fi = 'feature_importance_engineered',\n","                features = X_feature_engineered)   #change here"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["ACC:0.8704827796512967|F1:0.8686430176531006|AUROC:0.9439847412700422|AUPRC:0.9359611161490434"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Engineered Data with Feature Engineering"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["When use 9-17 most important features, the model has higher accuracy. As a results, 17 most important features + 4 extra vital signs  = 21 features"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["X_feature_engineered_fs = ['RR_dev_3', 'Temp_dev_3', 'SaO2', 'Magnesium', 'MAP', \n","                            'gender', 'Potassium', 'Chloride', 'PTT', 'SBP', \n","                            'HCO3', 'BaseExcess', 'Glucose', 'WBC', 'BUN', \n","                            'Calcium', 'Platelet', \n","                            'RR', 'Temp', 'DBP', 'HR']\n","\n","y_feature = ['sepsis']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#load data from Cinc2019\n","data_path_c = \"../../datasets/Cinc2019/engineered_all/\"  \n","train_nonsepsis_c = np.load('../data/data_Cinc2019/train_nonsepsis.npy')\n","train_sepsis_c = np.load('../data/data_Cinc2019/train_sepsis.npy')\n","\n","# load data from MIMIC-III\n","data_path_m = \"../../datasets/MIMICIII/adults/engineered_all/\"  \n","train_nonsepsis_m = np.load('../data/data_mimiciii/train_nonsepsis.npy')\n","train_sepsis_m = np.load('../data/data_mimiciii/train_sepsis.npy')\n","\n","# 5-fold cross validation was implemented and five XGBoost models were produced\n","sss = StratifiedShuffleSplit(n_splits=5, test_size = 3/17, random_state=np.random.seed(12306)) # val/train = 0.15/0.7\n","for (k, (train0_index, val0_index)), (k, (train1_index, val1_index)), (k, (train2_index, val2_index)), (k, (train3_index, val3_index))\\\n","     in zip(enumerate(sss.split(train_nonsepsis_c, np.zeros(train_nonsepsis_c.shape))), enumerate(sss.split(train_sepsis_c, np.zeros(train_sepsis_c.shape))), enumerate(sss.split(train_nonsepsis_m, np.zeros(train_nonsepsis_m.shape))), enumerate(sss.split(train_sepsis_m, np.zeros(train_sepsis_m.shape)))):\n","\n","    print('---Fold{}/5---'.format(k+1))\n","\n","    # read data from Cinc2019\n","    train_set_c = np.append((train_nonsepsis_c[train0_index])[:2052], (train_sepsis_c[train1_index])[:2052])\n","    val_set_c = np.append((train_nonsepsis_c[val0_index])[:440], (train_sepsis_c[val1_index][:440]))\n","    train_engineered_c = gather_dfs('../../datasets/Cinc2019/engineered_all/',train_set_c)\n","    val_engineered_c = gather_dfs('../../datasets/Cinc2019/engineered_all/',val_set_c)\n","\n","    # read data from MIMIC-III \n","    train_set_m = np.append((train_nonsepsis_m[train2_index][:1320]), (train_sepsis_m[train3_index])[:1320])\n","    val_set_m = np.append((train_nonsepsis_m[val2_index])[:283], (train_sepsis_m[val3_index])[:283])\n","    train_engineered_m = gather_dfs('../../datasets/MIMICIII/adults/engineered_all/',train_set_m)\n","    val_engineered_m = gather_dfs('../../datasets/MIMICIII/adults/engineered_all/',val_set_m)\n","\n","    # combine two datasets\n","    train_engineered_both = pd.concat([train_engineered_c,train_engineered_m], ignore_index=True)\n","    train_engineered = expand_sepsis_label(train_engineered_both) #balance sepsis and non-sepsis labels\n","    val_engineered_both = pd.concat([val_engineered_c,val_engineered_m], ignore_index=True)\n","    val_engineered = expand_sepsis_label(val_engineered_both) #balance sepsis and non-sepsis labels\n","\n","    x_train= train_engineered[X_feature_engineered_fs]\n","    y_train = train_engineered[y_feature]\n","\n","    x_val = val_engineered[X_feature_engineered_fs]\n","    y_val = val_engineered[y_feature]\n","\n","\n","    print('---Start training process---')\n","    train_model(k, x_train, y_train, x_val, y_val, \n","                save_model_dir = './trained_models/EDWFS/',\n","                fig_name_val = 'val_w_fs_engineered',\n","                fig_name_fi = 'feature_importance_engineered',\n","                features = X_feature_engineered_fs)   #change here"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["ACC:0.7901833103471321|F1:0.7826728469761315|AUROC:0.8679477638756825|AUPRC:0.8700686539486396"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Performance on Test data"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Score Function"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["#!/usr/bin/env python\n","\n","# This file contains functions for evaluating algorithms for the 2019 PhysioNet/\n","# CinC Challenge. You can run it as follows:\n","#\n","#   python evaluate_sepsis_score.py labels predictions scores.csv\n","#\n","# where 'labels' is a directory containing files with labels, 'predictions' is a\n","# directory containing files with predictions, and 'scores.csv' (optional) is a\n","# collection of scores for the predictions.\n","\n","################################################################################\n","\n","# The evaluate_scores function computes a normalized utility score for a cohort\n","# of patients along with several traditional scoring metrics.\n","#\n","# Inputs:\n","#   'label_directory' is a directory of pipe-delimited text files containing a\n","#   binary vector of labels for whether a patient is not septic (0) or septic\n","#   (1) for each time interval.\n","#\n","#   'prediction_directory' is a directory of pipe-delimited text files, where\n","#   the first column of the file gives the predicted probability that the\n","#   patient is septic at each time, and the second column of the file is a\n","#   binarized version of this vector. Note that there must be a prediction for\n","#   every label.\n","#\n","# Outputs:\n","#   'auroc' is the area under the receiver operating characteristic curve\n","#   (AUROC).\n","#\n","#   'auprc' is the area under the precision recall curve (AUPRC).\n","#\n","#   'accuracy' is accuracy.\n","#\n","#   'f_measure' is F-measure.\n","#\n","#   'normalized_observed_utility' is a normalized utility-based measure that we\n","#   created for the Challenge. This score is normalized so that a perfect score\n","#   is 1 and no positive predictions is 0.\n","#\n","# Example:\n","#   Omitted due to length. See the below examples.\n","\n","import numpy as np, os, os.path, sys, warnings\n","\n","def evaluate_sepsis_score(label_directory, prediction_directory):\n","    # Set parameters.\n","    label_header       = 'sepsis'\n","    prediction_header  = 'PredictedLabel'\n","    probability_header = 'PredictedProbability'\n","\n","    dt_early   = -12\n","    dt_optimal = -6\n","    dt_late    = 3\n","\n","    max_u_tp = 1\n","    min_u_fn = -2\n","    u_fp     = -0.05\n","    u_tn     = 0\n","\n","    # Find label and prediction files.\n","    label_files = []\n","    for f in os.listdir(label_directory):\n","        g = os.path.join(label_directory, f)\n","        if os.path.isfile(g) and not f.lower().startswith('.') and f.lower().endswith('csv'):\n","            label_files.append(g)\n","    label_files = sorted(label_files)\n","\n","    prediction_files = []\n","    for f in os.listdir(prediction_directory):\n","        g = os.path.join(prediction_directory, f)\n","        if os.path.isfile(g) and not f.lower().startswith('.') and f.lower().endswith('csv'):\n","            prediction_files.append(g)\n","    prediction_files = sorted(prediction_files)\n","\n","    if len(label_files) != len(prediction_files):\n","        raise Exception('Numbers of label and prediction files must be the same.')\n","\n","    # Load labels and predictions.\n","    num_files            = len(label_files)\n","    cohort_labels        = []\n","    cohort_predictions   = []\n","    cohort_probabilities = []\n","\n","    for k in range(num_files):\n","        labels        = load_column(label_files[k], label_header, ',')\n","        predictions   = load_column(prediction_files[k], prediction_header, ',')\n","        probabilities = load_column(prediction_files[k], probability_header, ',')\n","\n","        # Check labels and predictions for errors.\n","        if not (len(labels) == len(predictions) and len(predictions) == len(probabilities)):\n","            raise Exception('Numbers of labels and predictions for a file must be the same.')\n","\n","        num_rows = len(labels)\n","\n","        for i in range(num_rows):\n","            if labels[i] not in (0, 1):\n","                raise Exception('Labels must satisfy label == 0 or label == 1.')\n","\n","            if predictions[i] not in (0, 1):\n","                raise Exception('Predictions must satisfy prediction == 0 or prediction == 1.')\n","\n","            if not 0 <= probabilities[i] <= 1:\n","                warnings.warn('Probabilities do not satisfy 0 <= probability <= 1.')\n","\n","        if 0 < np.sum(predictions) < num_rows:\n","            min_probability_positive = np.min(probabilities[predictions == 1])\n","            max_probability_negative = np.max(probabilities[predictions == 0])\n","\n","            if min_probability_positive <= max_probability_negative:\n","                warnings.warn('Predictions are inconsistent with probabilities, i.e., a positive prediction has a lower (or equal) probability than a negative prediction.')\n","\n","        # Record labels and predictions.\n","        cohort_labels.append(labels)\n","        cohort_predictions.append(predictions)\n","        cohort_probabilities.append(probabilities)\n","\n","    # Compute AUC, accuracy, and F-measure.\n","    labels        = np.concatenate(cohort_labels)\n","    predictions   = np.concatenate(cohort_predictions)\n","    probabilities = np.concatenate(cohort_probabilities)\n","\n","    auroc, auprc        = compute_auc(labels, probabilities)\n","    accuracy, f_measure = compute_accuracy_f_measure(labels, predictions)\n","\n","    # Compute utility.\n","    observed_utilities = np.zeros(num_files)\n","    best_utilities     = np.zeros(num_files)\n","    worst_utilities    = np.zeros(num_files)\n","    inaction_utilities = np.zeros(num_files)\n","\n","    for k in range(num_files):\n","        labels = cohort_labels[k]\n","        num_rows          = len(labels)\n","        observed_predictions = cohort_predictions[k]\n","        best_predictions     = np.zeros(num_rows)\n","        worst_predictions    = np.zeros(num_rows)\n","        inaction_predictions = np.zeros(num_rows)\n","\n","        if np.any(labels):\n","            t_sepsis = np.argmax(labels) - dt_optimal\n","            best_predictions[max(0, t_sepsis + dt_early) : min(t_sepsis + dt_late + 1, num_rows)] = 1\n","        worst_predictions = 1 - best_predictions\n","\n","        observed_utilities[k] = compute_prediction_utility(labels, observed_predictions, dt_early, dt_optimal, dt_late, max_u_tp, min_u_fn, u_fp, u_tn)\n","        best_utilities[k]     = compute_prediction_utility(labels, best_predictions, dt_early, dt_optimal, dt_late, max_u_tp, min_u_fn, u_fp, u_tn)\n","        worst_utilities[k]    = compute_prediction_utility(labels, worst_predictions, dt_early, dt_optimal, dt_late, max_u_tp, min_u_fn, u_fp, u_tn)\n","        inaction_utilities[k] = compute_prediction_utility(labels, inaction_predictions, dt_early, dt_optimal, dt_late, max_u_tp, min_u_fn, u_fp, u_tn)\n","\n","    unnormalized_observed_utility = np.sum(observed_utilities)\n","    unnormalized_best_utility     = np.sum(best_utilities)\n","    unnormalized_worst_utility    = np.sum(worst_utilities)\n","    unnormalized_inaction_utility = np.sum(inaction_utilities)\n","\n","    normalized_observed_utility = (unnormalized_observed_utility - unnormalized_inaction_utility) / (unnormalized_best_utility - unnormalized_inaction_utility)\n","\n","    return auroc, auprc, accuracy, f_measure, normalized_observed_utility\n","\n","# The load_column function loads a column from a table.\n","#\n","# Inputs:\n","#   'filename' is a string containing a filename.\n","#\n","#   'header' is a string containing a header.\n","#\n","# Outputs:\n","#   'column' is a vector containing a column from the file with the given\n","#   header.\n","#\n","# Example:\n","#   Omitted.\n","\n","def load_column(filename, header, delimiter):\n","    column = []\n","    with open(filename, 'r') as f:\n","        for i, l in enumerate(f):\n","            arrs = l.strip().split(delimiter)\n","            if i == 0:\n","                try:\n","                    j = arrs.index(header)\n","                except:\n","                    raise Exception('{} must contain column with header {} containing numerical entries.'.format(filename, header))\n","            else:\n","                if len(arrs[j]):\n","                    column.append(float(arrs[j]))\n","    return np.array(column)\n","\n","# The compute_auc function computes AUROC and AUPRC as well as other summary\n","# statistics (TP, FP, FN, TN, TPR, TNR, PPV, NPV, etc.) that can be exposed\n","# from this function.\n","#\n","# Inputs:\n","#   'labels' is a binary vector, where labels[i] == 0 if the patient is not\n","#   labeled as septic at time i and labels[i] == 1 if the patient is labeled as\n","#   septic at time i.\n","#\n","#   'predictions' is a probability vector, where predictions[i] gives the\n","#   predicted probability that the patient is septic at time i.  Note that there\n","#   must be a prediction for every label, i.e, len(labels) ==\n","#   len(predictions).\n","#\n","# Outputs:\n","#   'auroc' is a scalar that gives the AUROC of the algorithm using its\n","#   predicted probabilities, where specificity is interpolated for intermediate\n","#   sensitivity values.\n","#\n","#   'auprc' is a scalar that gives the AUPRC of the algorithm using its\n","#   predicted probabilities, where precision is a piecewise constant function of\n","#   recall.\n","#\n","# Example:\n","#   In [1]: labels = [0, 0, 0, 0, 1, 1]\n","#   In [2]: predictions = [0.3, 0.4, 0.6, 0.7, 0.8, 0.8]\n","#   In [3]: auroc, auprc = compute_auc(labels, predictions)\n","#   In [4]: auroc\n","#   Out[4]: 1.0\n","#   In [5]: auprc\n","#   Out[5]: 1.0\n","\n","def compute_auc(labels, predictions, check_errors=True):\n","    # Check inputs for errors.\n","    if check_errors:\n","        if len(predictions) != len(labels):\n","            raise Exception('Numbers of predictions and labels must be the same.')\n","\n","        for label in labels:\n","            if not label in (0, 1):\n","                raise Exception('Labels must satisfy label == 0 or label == 1.')\n","\n","        for prediction in predictions:\n","            if not 0 <= prediction <= 1:\n","                warnings.warn('Predictions do not satisfy 0 <= prediction <= 1.')\n","\n","    # Find prediction thresholds.\n","    thresholds = np.unique(predictions)[::-1]\n","    if thresholds[0] != 1:\n","        thresholds = np.insert(thresholds, 0, 1)\n","    if thresholds[-1] == 0:\n","        thresholds = thresholds[:-1]\n","\n","    n = len(labels)\n","    m = len(thresholds)\n","\n","    # Populate contingency table across prediction thresholds.\n","    tp = np.zeros(m)\n","    fp = np.zeros(m)\n","    fn = np.zeros(m)\n","    tn = np.zeros(m)\n","\n","    # Find indices that sort the predicted probabilities from largest to\n","    # smallest.\n","    idx = np.argsort(predictions)[::-1]\n","\n","    i = 0\n","    for j in range(m):\n","        # Initialize contingency table for j-th prediction threshold.\n","        if j == 0:\n","            tp[j] = 0\n","            fp[j] = 0\n","            fn[j] = np.sum(labels)\n","            tn[j] = n - fn[j]\n","        else:\n","            tp[j] = tp[j - 1]\n","            fp[j] = fp[j - 1]\n","            fn[j] = fn[j - 1]\n","            tn[j] = tn[j - 1]\n","\n","        # Update contingency table for i-th largest predicted probability.\n","        while i < n and predictions[idx[i]] >= thresholds[j]:\n","            if labels[idx[i]]:\n","                tp[j] += 1\n","                fn[j] -= 1\n","            else:\n","                fp[j] += 1\n","                tn[j] -= 1\n","            i += 1\n","\n","    # Summarize contingency table.\n","    tpr = np.zeros(m)\n","    tnr = np.zeros(m)\n","    ppv = np.zeros(m)\n","    npv = np.zeros(m)\n","\n","    for j in range(m):\n","        if tp[j] + fn[j]:\n","            tpr[j] = tp[j] / (tp[j] + fn[j])\n","        else:\n","            tpr[j] = 1\n","        if fp[j] + tn[j]:\n","            tnr[j] = tn[j] / (fp[j] + tn[j])\n","        else:\n","            tnr[j] = 1\n","        if tp[j] + fp[j]:\n","            ppv[j] = tp[j] / (tp[j] + fp[j])\n","        else:\n","            ppv[j] = 1\n","        if fn[j] + tn[j]:\n","            npv[j] = tn[j] / (fn[j] + tn[j])\n","        else:\n","            npv[j] = 1\n","\n","    # Compute AUROC as the area under a piecewise linear function with TPR /\n","    # sensitivity (x-axis) and TNR / specificity (y-axis) and AUPRC as the area\n","    # under a piecewise constant with TPR / recall (x-axis) and PPV / precision\n","    # (y-axis).\n","    auroc = 0\n","    auprc = 0\n","    for j in range(m-1):\n","        auroc += 0.5 * (tpr[j + 1] - tpr[j]) * (tnr[j + 1] + tnr[j])\n","        auprc += (tpr[j + 1] - tpr[j]) * ppv[j + 1]\n","\n","    return auroc, auprc\n","\n","# The compute_accuracy_f_measure function computes the accuracy and F-measure\n","# for a patient.\n","#\n","# Inputs:\n","#   'labels' is a binary vector, where labels[i] == 0 if the patient is not\n","#   labeled as septic at time i and labels[i] == 1 if the patient is labeled as\n","#   septic at time i.\n","#\n","#   'predictions' is a binary vector, where predictions[i] == 0 if the patient\n","#   is not predicted to be septic at time i and predictions[i] == 1 if the\n","#   patient is predicted to be septic at time i.  Note that there must be a\n","#   prediction for every label, i.e, len(labels) == len(predictions).\n","#\n","# Output:\n","#   'accuracy' is a scalar that gives the accuracy of the predictions using its\n","#   binarized predictions.\n","#\n","#   'f_measure' is a scalar that gives the F-measure of the predictions using its\n","#   binarized predictions.\n","#\n","# Example:\n","#   In [1]: labels = [0, 0, 0, 0, 1, 1]\n","#   In [2]: predictions = [0, 0, 1, 1, 1, 1]\n","#   In [3]: accuracy, f_measure = compute_accuracy_f_measure(labels, predictions)\n","#   In [4]: accuracy\n","#   Out[4]: 0.666666666667\n","#   In [5]: f_measure\n","#   Out[5]: 0.666666666667\n","\n","def compute_accuracy_f_measure(labels, predictions, check_errors=True):\n","    # Check inputs for errors.\n","    if check_errors:\n","        if len(predictions) != len(labels):\n","            raise Exception('Numbers of predictions and labels must be the same.')\n","\n","        for label in labels:\n","            if not label in (0, 1):\n","                raise Exception('Labels must satisfy label == 0 or label == 1.')\n","\n","        for prediction in predictions:\n","            if not prediction in (0, 1):\n","                raise Exception('Predictions must satisfy prediction == 0 or prediction == 1.')\n","\n","    # Populate contingency table.\n","    n = len(labels)\n","    tp = 0\n","    fp = 0\n","    fn = 0\n","    tn = 0\n","\n","    for i in range(n):\n","        if labels[i] and predictions[i]:\n","            tp += 1\n","        elif not labels[i] and predictions[i]:\n","            fp += 1\n","        elif labels[i] and not predictions[i]:\n","            fn += 1\n","        elif not labels[i] and not predictions[i]:\n","            tn += 1\n","\n","    # Summarize contingency table.\n","    if tp + fp + fn + tn:\n","        accuracy = float(tp + tn) / float(tp + fp + fn + tn)\n","    else:\n","        accuracy = 1.0\n","\n","    if 2 * tp + fp + fn:\n","        f_measure = float(2 * tp) / float(2 * tp + fp + fn)\n","    else:\n","        f_measure = 1.0\n","\n","    return accuracy, f_measure\n","\n","# The compute_prediction_utility function computes the total time-dependent\n","# utility for a patient.\n","#\n","# Inputs:\n","#   'labels' is a binary vector, where labels[i] == 0 if the patient is not\n","#   labeled as septic at time i and labels[i] == 1 if the patient is labeled as\n","#   septic at time i.\n","#\n","#   'predictions' is a binary vector, where predictions[i] == 0 if the patient\n","#   is not predicted to be septic at time i and predictions[i] == 1 if the\n","#   patient is predicted to be septic at time i.  Note that there must be a\n","#   prediction for every label, i.e, len(labels) == len(predictions).\n","#\n","# Output:\n","#   'utility' is a scalar that gives the total time-dependent utility of the\n","#   algorithm using its binarized predictions.\n","#\n","# Example:\n","#   In [1]: labels = [0, 0, 0, 0, 1, 1]\n","#   In [2]: predictions = [0, 0, 1, 1, 1, 1]\n","#   In [3]: utility = compute_prediction_utility(labels, predictions)\n","#   In [4]: utility\n","#   Out[4]: 3.388888888888889\n","\n","def compute_prediction_utility(labels, predictions, dt_early=-12, dt_optimal=-6, dt_late=3.0, max_u_tp=1, min_u_fn=-2, u_fp=-0.05, u_tn=0, check_errors=True):\n","    # Check inputs for errors.\n","    if check_errors:\n","        if len(predictions) != len(labels):\n","            raise Exception('Numbers of predictions and labels must be the same.')\n","\n","        for label in labels:\n","            if not label in (0, 1):\n","                raise Exception('Labels must satisfy label == 0 or label == 1.')\n","\n","        for prediction in predictions:\n","            if not prediction in (0, 1):\n","                raise Exception('Predictions must satisfy prediction == 0 or prediction == 1.')\n","\n","        if dt_early >= dt_optimal:\n","            raise Exception('The earliest beneficial time for predictions must be before the optimal time.')\n","\n","        if dt_optimal >= dt_late:\n","            raise Exception('The optimal time for predictions must be before the latest beneficial time.')\n","\n","    # Does the patient eventually have sepsis?\n","    if np.any(labels):\n","        is_septic = True\n","        t_sepsis = np.argmax(labels) - dt_optimal\n","    else:\n","        is_septic = False\n","        t_sepsis = float('inf')\n","\n","    n = len(labels)\n","\n","    # Define slopes and intercept points for utility functions of the form\n","    # u = m * t + b.\n","    m_1 = float(max_u_tp) / float(dt_optimal - dt_early)\n","    b_1 = -m_1 * dt_early\n","    m_2 = float(-max_u_tp) / float(dt_late - dt_optimal)\n","    b_2 = -m_2 * dt_late\n","    m_3 = float(min_u_fn) / float(dt_late - dt_optimal)\n","    b_3 = -m_3 * dt_optimal\n","\n","    # Compare predicted and true conditions.\n","    u = np.zeros(n)\n","    for t in range(n):\n","        if t <= t_sepsis + dt_late:\n","            # TP\n","            if is_septic and predictions[t]:\n","                if t <= t_sepsis + dt_optimal:\n","                    u[t] = max(m_1 * (t - t_sepsis) + b_1, u_fp)\n","                elif t <= t_sepsis + dt_late:\n","                    u[t] = m_2 * (t - t_sepsis) + b_2\n","            # FP\n","            elif not is_septic and predictions[t]:\n","                u[t] = u_fp\n","            # FN\n","            elif is_septic and not predictions[t]:\n","                if t <= t_sepsis + dt_optimal:\n","                    u[t] = 0\n","                elif t <= t_sepsis + dt_late:\n","                    u[t] = m_3 * (t - t_sepsis) + b_3\n","            # TN\n","            elif not is_septic and not predictions[t]:\n","                u[t] = u_tn\n","\n","    # Find total utility for patient.\n","    return np.sum(u)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Data Processing Functions"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["def save_challenge_predictions(file, scores, labels):\n","    with open(file, 'w') as f:\n","        f.write('PredictedProbability,PredictedLabel\\n')\n","        for (s, l) in zip(scores, labels):\n","            f.write('%g,%d\\n' % (s, l))\n","\n","def save_challenge_testlabel(file, labels):\n","    with open(file, 'w') as f:\n","        f.write('sepsis\\n')\n","        for l in labels:\n","            f.write('%d\\n' % l)\n","\n","def load_model_predict(X_test, k_fold, path):\n","    \"ensemble the five XGBoost models by averaging their output probabilities\"\n","    test_pred = np.zeros((X_test.shape[0], k_fold))\n","    X_test = xgb.DMatrix(X_test)\n","    for k in range(k_fold):\n","        # load the model\n","        model_path_name = path + 'model{}.mdl'.format(k+1) \n","        loaded_model = xgb.Booster(model_file = model_path_name)\n","        # predict\n","        y_test_pred = loaded_model.predict(X_test)\n","        test_pred[:, k] = y_test_pred # save prediction results 5 times\n","    test_pred = pd.DataFrame(test_pred)\n","    result_pro = test_pred.mean(axis=1)\n","\n","    return result_pro\n","\n","def feature_extraction(case, data_features):\n","    labels = np.array(case['sepsis'])\n","    features = case[data_features]\n","    if 'time' in features.columns:\n","        features = features.drop(columns=['time'],axis = 1)\n","\n","    return  features, labels    \n","\n","def predict(data_set,\n","            data_dir,\n","            save_prediction_dir,\n","            save_label_dir,\n","            model_path,\n","            risk_threshold,\n","            data_features\n","            ):\n","    for csv in tqdm(data_set):\n","        csv = csv.replace('psv','csv')\n","        patient = pd.read_csv(data_dir+csv, sep=',')\n","        features, labels = feature_extraction(patient, data_features)\n","\n","        predict_pro = load_model_predict(features, k_fold = 5, path = model_path)\n","        PredictedProbability = np.array(predict_pro)\n","        PredictedLabel = [0 if i <= risk_threshold else 1 for i in predict_pro]\n","\n","        save_prediction_name = save_prediction_dir + csv\n","        save_challenge_predictions(save_prediction_name, PredictedProbability, PredictedLabel)\n","        save_testlabel_name = save_label_dir + csv\n","        save_challenge_testlabel(save_testlabel_name, labels)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Baseline Data Without Feature Selection"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["!rm -r -f ./prediction\n","!rm -r -f ./label\n","!mkdir -p ./prediction\n","!mkdir -p ./label"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1446/1446 [00:29<00:00, 49.24it/s]\n"]},{"name":"stdout","output_type":"stream","text":["AUROC|AUPRC|Accuracy|F-measure|Utility\n","0.6430027131587179|0.1584866629878091|0.46124377795980087|0.18180774309609019|0.5792420020420319\n"]}],"source":["test_set = np.load('../data/data_both/test_set.npy')\n","test_data_path = '../data/data_both/test_baseline/' #change here\n","prediction_directory = './prediction/'\n","label_directory = './label/'\n","model_path = './trained_models/BDWOFS/' #change here\n","\n","predict(test_set, test_data_path, prediction_directory, label_directory, model_path, 0.5, X_feature_baseline) # change feature here \n","\n","auroc, auprc, accuracy, f_measure, utility = evaluate_sepsis_score(label_directory, prediction_directory)\n","output_string = 'AUROC|AUPRC|Accuracy|F-measure|Utility\\n{}|{}|{}|{}|{}'.format(\n","                auroc, auprc, accuracy, f_measure, utility)\n","print(output_string)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Baseline Data with Feature Selection"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["!rm -r -f ./prediction\n","!rm -r -f ./label\n","!mkdir -p ./prediction\n","!mkdir -p ./label"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1446/1446 [00:31<00:00, 46.19it/s]\n"]},{"name":"stdout","output_type":"stream","text":["AUROC|AUPRC|Accuracy|F-measure|Utility\n","0.6051262498204644|0.13278556543312744|0.3987524415600781|0.163622339866073|0.5454607334297628\n"]}],"source":["test_set = np.load('../data/data_both/test_set.npy')\n","test_data_path = '../data/data_both/test_baseline/' #change here\n","prediction_directory = './prediction/'\n","label_directory = './label/'\n","model_path = './trained_models/BDWFS/' #change here\n","\n","predict(test_set, test_data_path, prediction_directory, label_directory, model_path, 0.5, X_feature_baseline_fs) # change feature here \n","\n","auroc, auprc, accuracy, f_measure, utility = evaluate_sepsis_score(label_directory, prediction_directory)\n","output_string = 'AUROC|AUPRC|Accuracy|F-measure|Utility\\n{}|{}|{}|{}|{}'.format(\n","                auroc, auprc, accuracy, f_measure, utility)\n","print(output_string)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Engineered Data without Feature Selection"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["!rm -r -f ./prediction\n","!rm -r -f ./label\n","!mkdir -p ./prediction\n","!mkdir -p ./label"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1446/1446 [00:40<00:00, 35.63it/s]\n"]},{"name":"stdout","output_type":"stream","text":["AUROC|AUPRC|Accuracy|F-measure|Utility\n","0.9570821284661094|0.6842095605923605|0.8983806943481822|0.5730170496664195|0.793941440483281\n"]}],"source":["test_set = np.load('../data/data_both/test_set.npy')\n","test_data_path = '../data/data_both/test_engineered/' #change here\n","prediction_directory = './prediction/'\n","label_directory = './label/'\n","model_path = './trained_models/EDWOFS/' #change here\n","\n","predict(test_set, test_data_path, prediction_directory, label_directory, model_path, 0.5, X_feature_engineered) # change feature here \n","\n","auroc, auprc, accuracy, f_measure, utility = evaluate_sepsis_score(label_directory, prediction_directory)\n","output_string = 'AUROC|AUPRC|Accuracy|F-measure|Utility\\n{}|{}|{}|{}|{}'.format(\n","                auroc, auprc, accuracy, f_measure, utility)\n","print(output_string)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Engineered Data with Feature Selection"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["!rm -r -f ./prediction\n","!rm -r -f ./label\n","!mkdir -p ./prediction\n","!mkdir -p ./label"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1446/1446 [00:36<00:00, 39.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["AUROC|AUPRC|Accuracy|F-measure|Utility\n","0.8891115972964225|0.5284534205776364|0.8372377291916073|0.42544483985765125|0.6983786054624351\n"]}],"source":["test_set = np.load('../data/data_both/test_set.npy')\n","test_data_path = '../data/data_both/test_engineered/' #change here\n","prediction_directory = './prediction/'\n","label_directory = './label/'\n","model_path = './trained_models/EDWFS/' #change here\n","\n","predict(test_set, test_data_path, prediction_directory, label_directory, model_path, 0.5, X_feature_engineered_fs) # change feature here \n","\n","auroc, auprc, accuracy, f_measure, utility = evaluate_sepsis_score(label_directory, prediction_directory)\n","output_string = 'AUROC|AUPRC|Accuracy|F-measure|Utility\\n{}|{}|{}|{}|{}'.format(\n","                auroc, auprc, accuracy, f_measure, utility)\n","print(output_string)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Test Real Neonatal Data"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### BDWOFS"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["!rm -r -f ./prediction\n","!rm -r -f ./label\n","!mkdir -p ./prediction\n","!mkdir -p ./label"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 226/226 [00:06<00:00, 32.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["AUROC|AUPRC|Accuracy|F-measure|Utility\n","0.5335066020302109|0.041338095181773116|0.718327125277005|0.07979051139864449|0.13518218455274414\n"]}],"source":["# load test data\n","test_set = np.load('../../models_neoantes/data/test_set_balanced.npy')\n","test_data_path = '../../datasets/MIMICIII/neonates/baseline_all/' \n","\n","# pathes\n","prediction_directory = './prediction/'\n","label_directory = './label/'\n","model_path = './trained_models/BDWOFS/' \n","\n","predict(test_set, test_data_path, prediction_directory, label_directory, model_path, 0.5, X_feature_baseline)\n","\n","auroc, auprc, accuracy, f_measure, utility = evaluate_sepsis_score(label_directory, prediction_directory)\n","output_string = 'AUROC|AUPRC|Accuracy|F-measure|Utility\\n{}|{}|{}|{}|{}'.format(\n","                auroc, auprc, accuracy, f_measure, utility)\n","print(output_string)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### BDWFS"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["!rm -r -f ./prediction\n","!rm -r -f ./label\n","!mkdir -p ./prediction\n","!mkdir -p ./label"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 226/226 [00:06<00:00, 33.67it/s]\n"]},{"name":"stdout","output_type":"stream","text":["AUROC|AUPRC|Accuracy|F-measure|Utility\n","0.5076501931378806|0.037213712441160736|0.05912584280258381|0.07198995489001535|0.2580747018987079\n"]}],"source":["# load test data\n","test_set = np.load('../../models_neoantes/data/test_set_balanced.npy')\n","test_data_path = '../../datasets/MIMICIII/neonates/baseline_all/' \n","\n","# pathes\n","prediction_directory = './prediction/'\n","label_directory = './label/'\n","model_path = './trained_models/BDWFS/' \n","\n","predict(test_set, test_data_path, prediction_directory, label_directory, model_path, 0.5, X_feature_baseline_fs)\n","\n","auroc, auprc, accuracy, f_measure, utility = evaluate_sepsis_score(label_directory, prediction_directory)\n","output_string = 'AUROC|AUPRC|Accuracy|F-measure|Utility\\n{}|{}|{}|{}|{}'.format(\n","                auroc, auprc, accuracy, f_measure, utility)\n","print(output_string)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### EDWOFS"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["!rm -r -f ./prediction\n","!rm -r -f ./label\n","!mkdir -p ./prediction\n","!mkdir -p ./label"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 226/226 [00:08<00:00, 27.20it/s]\n"]},{"name":"stdout","output_type":"stream","text":["AUROC|AUPRC|Accuracy|F-measure|Utility\n","0.9138986026434371|0.37454008785778076|0.8797680230091|0.323966065747614|0.6424446383314637\n"]}],"source":["# load test data\n","test_set = np.load('../../models_neoantes/data/test_set_balanced.npy')\n","test_data_path = '../../datasets/MIMICIII/neonates/engineered_all/' \n","\n","# pathes\n","prediction_directory = './prediction/'\n","label_directory = './label/'\n","model_path = './trained_models/EDWOFS/' \n","\n","predict(test_set, test_data_path, prediction_directory, label_directory, model_path, 0.5, X_feature_engineered)\n","\n","auroc, auprc, accuracy, f_measure, utility = evaluate_sepsis_score(label_directory, prediction_directory)\n","output_string = 'AUROC|AUPRC|Accuracy|F-measure|Utility\\n{}|{}|{}|{}|{}'.format(\n","                auroc, auprc, accuracy, f_measure, utility)\n","print(output_string)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### EDWFS"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["!rm -r -f ./prediction\n","!rm -r -f ./label\n","!mkdir -p ./prediction\n","!mkdir -p ./label"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 226/226 [00:07<00:00, 29.07it/s]\n"]},{"name":"stdout","output_type":"stream","text":["AUROC|AUPRC|Accuracy|F-measure|Utility\n","0.7864595194319878|0.25652378883274607|0.06110613418831628|0.07316732604142424|0.27419502264323403\n"]}],"source":["# load test data\n","test_set = np.load('../../models_neoantes/data/test_set_balanced.npy')\n","test_data_path = '../../datasets/MIMICIII/neonates/engineered_all/' \n","\n","# pathes\n","prediction_directory = './prediction/'\n","label_directory = './label/'\n","model_path = './trained_models/EDWFS/' \n","\n","predict(test_set, test_data_path, prediction_directory, label_directory, model_path, 0.5, X_feature_engineered_fs)\n","\n","auroc, auprc, accuracy, f_measure, utility = evaluate_sepsis_score(label_directory, prediction_directory)\n","output_string = 'AUROC|AUPRC|Accuracy|F-measure|Utility\\n{}|{}|{}|{}|{}'.format(\n","                auroc, auprc, accuracy, f_measure, utility)\n","print(output_string)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Test Artificial Neonatal Data\n","### BDWOFS"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["!rm -r -f ./prediction\n","!rm -r -f ./label\n","!mkdir -p ./prediction\n","!mkdir -p ./label"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 226/226 [00:07<00:00, 31.09it/s]\n"]},{"name":"stdout","output_type":"stream","text":["AUROC|AUPRC|Accuracy|F-measure|Utility\n","0.7428517542833528|0.1048675334762386|0.8918151556686901|0.18570375829034635|0.2604512027919731\n"]}],"source":["# load test data\n","test_set = np.load('../../artificial_neonatal_data/data/balanced_226/test_set_balanced.npy')\n","test_data_path = '../../artificial_neonatal_data/data/balanced_226/baseline_all/' \n","\n","# pathes\n","prediction_directory = './prediction/'\n","label_directory = './label/'\n","model_path = './trained_models/BDWOFS/' \n","\n","predict(test_set, test_data_path, prediction_directory, label_directory, model_path, 0.5, X_feature_baseline)\n","\n","auroc, auprc, accuracy, f_measure, utility = evaluate_sepsis_score(label_directory, prediction_directory)\n","output_string = 'AUROC|AUPRC|Accuracy|F-measure|Utility\\n{}|{}|{}|{}|{}'.format(\n","                auroc, auprc, accuracy, f_measure, utility)\n","print(output_string)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### BDWFS"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["!rm -r -f ./prediction\n","!rm -r -f ./label\n","!mkdir -p ./prediction\n","!mkdir -p ./label"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 226/226 [00:06<00:00, 32.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["AUROC|AUPRC|Accuracy|F-measure|Utility\n","0.5577729790643288|0.04626758253852482|0.16291364793420796|0.07697290294720932|0.2885786696580665\n"]}],"source":["# load test data\n","test_set = np.load('../../artificial_neonatal_data/data/balanced_226/test_set_balanced.npy')\n","test_data_path = '../../artificial_neonatal_data/data/balanced_226/baseline_all/' \n","\n","# pathes\n","prediction_directory = './prediction/'\n","label_directory = './label/'\n","model_path = './trained_models/BDWFS/' \n","\n","predict(test_set, test_data_path, prediction_directory, label_directory, model_path, 0.5, X_feature_baseline_fs)\n","\n","auroc, auprc, accuracy, f_measure, utility = evaluate_sepsis_score(label_directory, prediction_directory)\n","output_string = 'AUROC|AUPRC|Accuracy|F-measure|Utility\\n{}|{}|{}|{}|{}'.format(\n","                auroc, auprc, accuracy, f_measure, utility)\n","print(output_string)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### EDWSFS"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["!rm -r -f ./prediction\n","!rm -r -f ./label\n","!mkdir -p ./prediction\n","!mkdir -p ./label"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 226/226 [00:08<00:00, 27.18it/s]\n"]},{"name":"stdout","output_type":"stream","text":["AUROC|AUPRC|Accuracy|F-measure|Utility\n","0.8988109213836714|0.44374816597385736|0.9505580575680439|0.45698924731182794|0.47739831318293247\n"]}],"source":["# load test data\n","test_set = np.load('../../artificial_neonatal_data/data/balanced_226/test_set_balanced.npy')\n","test_data_path = '../../artificial_neonatal_data/data/balanced_226/engineered_all/' \n","\n","# pathes\n","prediction_directory = './prediction/'\n","label_directory = './label/'\n","model_path = './trained_models/EDWOFS/' \n","\n","predict(test_set, test_data_path, prediction_directory, label_directory, model_path, 0.5, X_feature_engineered)\n","\n","auroc, auprc, accuracy, f_measure, utility = evaluate_sepsis_score(label_directory, prediction_directory)\n","output_string = 'AUROC|AUPRC|Accuracy|F-measure|Utility\\n{}|{}|{}|{}|{}'.format(\n","                auroc, auprc, accuracy, f_measure, utility)\n","print(output_string)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### EDWFS"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["!rm -r -f ./prediction\n","!rm -r -f ./label\n","!mkdir -p ./prediction\n","!mkdir -p ./label"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 226/226 [00:05<00:00, 39.10it/s]\n"]},{"name":"stdout","output_type":"stream","text":["AUROC|AUPRC|Accuracy|F-measure|Utility\n","0.8147305967404469|0.34677461228986023|0.5512042294889368|0.12535775615340583|0.4800033237774731\n"]}],"source":["# load test data\n","test_set = np.load('../../artificial_neonatal_data/data/balanced_226/test_set_balanced.npy')\n","test_data_path = '../../artificial_neonatal_data/data/balanced_226/engineered_all/' \n","\n","# pathes\n","prediction_directory = './prediction/'\n","label_directory = './label/'\n","model_path = './trained_models/EDWFS/' \n","\n","predict(test_set, test_data_path, prediction_directory, label_directory, model_path, 0.5, X_feature_engineered_fs)\n","\n","auroc, auprc, accuracy, f_measure, utility = evaluate_sepsis_score(label_directory, prediction_directory)\n","output_string = 'AUROC|AUPRC|Accuracy|F-measure|Utility\\n{}|{}|{}|{}|{}'.format(\n","                auroc, auprc, accuracy, f_measure, utility)\n","print(output_string)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPfDNy3AegKhj9q2ICmADOR","provenance":[]},"kernelspec":{"display_name":"DL_Environment","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.13 (default, Mar 28 2022, 07:24:34) \n[Clang 12.0.0 ]"},"vscode":{"interpreter":{"hash":"fd901a71f1e124788c289e11a286c3218d50d6e5c83a9d223b7671fe76e12162"}}},"nbformat":4,"nbformat_minor":0}

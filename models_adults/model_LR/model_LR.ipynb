{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Import Libs"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1342,"status":"ok","timestamp":1666645465192,"user":{"displayName":"Jinyi Jin","userId":"06348382445328590699"},"user_tz":-120},"id":"dry8nMG76yb6"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import os\n","import random\n","import pickle\n","import joblib\n","from tqdm import tqdm\n","from sklearn.model_selection import GridSearchCV\n","from plot_metric.functions import BinaryClassification\n","from sklearn import linear_model, preprocessing\n","from sklearn.metrics import precision_recall_curve, auc, roc_curve, classification_report\n","from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['Latin Modern Roman']\n"]}],"source":["# check the system font\n","import matplotlib.font_manager as font_manager\n","font_manager.findSystemFonts(fontpaths=None, fontext='ttf')\n","\n","# add the font wanted\n","font_dir = ['../../Latin-Modern-Roman']\n","for font in font_manager.findSystemFonts(font_dir):\n","    font_manager.fontManager.addfont(font)\n","\n","# Set font family globally\n","plt.rcParams['font.family'] = 'Latin Modern Roman'\n","print(plt.rcParams['font.family'])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Feature Selection"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Baseline Data"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["X_feature_baseline = ['HR', 'SaO2', 'Temp', 'SBP', 'MAP', 'DBP', 'RR', 'BaseExcess', 'HCO3',\n","       'PH', 'BUN', 'Calcium', 'Chloride', 'Creatinine', 'Glucose', 'Lactic',\n","       'Magnesium', 'Potassium', 'PTT', 'WBC', 'Platelet', 'age', 'gender']\n","\n","y_feature = 'sepsis'"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["There are  23 Features inside baseline data with subject_id and sepsis excluded\n"]}],"source":["max_features_baseline = len(X_feature_baseline)\n","print('There are ',len(X_feature_baseline), 'Features inside baseline data with subject_id and sepsis excluded')"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/5 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["---Fold1/5---\n","Baseline Dataset 1: Accuracy on the training data is 0.6074441788727503\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|██        | 1/5 [00:17<01:11, 17.82s/it]"]},{"name":"stdout","output_type":"stream","text":["The 1 most significant feature is HR\n","The 2 most significant feature is SaO2\n","The 3 most significant feature is PH\n","The 4 most significant feature is DBP\n","The 5 most significant feature is RR\n","The 6 most significant feature is WBC\n","The 7 most significant feature is BUN\n","The 8 most significant feature is Glucose\n","The 9 most significant feature is MAP\n","The 10 most significant feature is HCO3\n","The 11 most significant feature is gender\n","The 12 most significant feature is Creatinine\n","The 13 most significant feature is Chloride\n","The 14 most significant feature is age\n","The 15 most significant feature is Magnesium\n","The 16 most significant feature is SBP\n","The 17 most significant feature is Lactic\n","The 18 most significant feature is Platelet\n","The 19 most significant feature is PTT\n","The 20 most significant feature is Potassium\n","The 21 most significant feature is BaseExcess\n","The 22 most significant feature is Calcium\n","---Fold2/5---\n","Baseline Dataset 2: Accuracy on the training data is 0.5842594646927126\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|████      | 2/5 [00:33<00:50, 16.78s/it]"]},{"name":"stdout","output_type":"stream","text":["The 1 most significant feature is HR\n","The 2 most significant feature is SaO2\n","The 3 most significant feature is PH\n","The 4 most significant feature is DBP\n","The 5 most significant feature is MAP\n","The 6 most significant feature is RR\n","The 7 most significant feature is Glucose\n","The 8 most significant feature is WBC\n","The 9 most significant feature is BUN\n","The 10 most significant feature is SBP\n","The 11 most significant feature is Creatinine\n","The 12 most significant feature is PTT\n","The 13 most significant feature is gender\n","The 14 most significant feature is Lactic\n","The 15 most significant feature is age\n","The 16 most significant feature is Chloride\n","The 17 most significant feature is Potassium\n","The 18 most significant feature is BaseExcess\n","The 19 most significant feature is Platelet\n","The 20 most significant feature is Magnesium\n","The 21 most significant feature is HCO3\n","The 22 most significant feature is Temp\n","---Fold3/5---\n","Baseline Dataset 3: Accuracy on the training data is 0.59864592394786\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|██████    | 3/5 [00:49<00:32, 16.31s/it]"]},{"name":"stdout","output_type":"stream","text":["The 1 most significant feature is HR\n","The 2 most significant feature is SaO2\n","The 3 most significant feature is PH\n","The 4 most significant feature is DBP\n","The 5 most significant feature is RR\n","The 6 most significant feature is BUN\n","The 7 most significant feature is MAP\n","The 8 most significant feature is Glucose\n","The 9 most significant feature is WBC\n","The 10 most significant feature is Magnesium\n","The 11 most significant feature is Chloride\n","The 12 most significant feature is Creatinine\n","The 13 most significant feature is HCO3\n","The 14 most significant feature is PTT\n","The 15 most significant feature is SBP\n","The 16 most significant feature is gender\n","The 17 most significant feature is age\n","The 18 most significant feature is Platelet\n","The 19 most significant feature is Lactic\n","The 20 most significant feature is Temp\n","The 21 most significant feature is Potassium\n","The 22 most significant feature is BaseExcess\n","---Fold4/5---\n","Baseline Dataset 4: Accuracy on the training data is 0.6030393457862084\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|████████  | 4/5 [01:02<00:15, 15.05s/it]"]},{"name":"stdout","output_type":"stream","text":["The 1 most significant feature is HR\n","The 2 most significant feature is SaO2\n","The 3 most significant feature is PH\n","The 4 most significant feature is DBP\n","The 5 most significant feature is MAP\n","The 6 most significant feature is RR\n","The 7 most significant feature is BUN\n","The 8 most significant feature is WBC\n","The 9 most significant feature is Glucose\n","The 10 most significant feature is SBP\n","The 11 most significant feature is Chloride\n","The 12 most significant feature is gender\n","The 13 most significant feature is PTT\n","The 14 most significant feature is Magnesium\n","The 15 most significant feature is HCO3\n","The 16 most significant feature is Creatinine\n","The 17 most significant feature is Lactic\n","The 18 most significant feature is Temp\n","The 19 most significant feature is BaseExcess\n","The 20 most significant feature is Calcium\n","The 21 most significant feature is Potassium\n","The 22 most significant feature is Platelet\n","---Fold5/5---\n","Baseline Dataset 5: Accuracy on the training data is 0.5916755773100705\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5/5 [01:15<00:00, 15.20s/it]"]},{"name":"stdout","output_type":"stream","text":["The 1 most significant feature is HR\n","The 2 most significant feature is SaO2\n","The 3 most significant feature is DBP\n","The 4 most significant feature is PH\n","The 5 most significant feature is RR\n","The 6 most significant feature is WBC\n","The 7 most significant feature is MAP\n","The 8 most significant feature is Glucose\n","The 9 most significant feature is BUN\n","The 10 most significant feature is Chloride\n","The 11 most significant feature is HCO3\n","The 12 most significant feature is gender\n","The 13 most significant feature is SBP\n","The 14 most significant feature is PTT\n","The 15 most significant feature is Lactic\n","The 16 most significant feature is age\n","The 17 most significant feature is Creatinine\n","The 18 most significant feature is Platelet\n","The 19 most significant feature is Potassium\n","The 20 most significant feature is Temp\n","The 21 most significant feature is Magnesium\n","The 22 most significant feature is BaseExcess\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# In Random Forest model, the data split in 5-fold crossvalidation is stored,\n","# It can be directly applied here\n","\n","for k in tqdm(range(5)):\n","\n","    print('---Fold{}/5---'.format(k+1))\n","\n","    # load the train and val data\n","    filename = '../data/data_both/kFold_baseline/fold{}/train.pickle'.format(k+1)\n","    with open(filename, 'rb') as f:\n","        train_baseline = pickle.load(f)\n","\n","    filename = '../data/data_both/kFold_baseline/fold{}/val.pickle'.format(k+1)\n","    with open(filename, 'rb') as f:\n","        val_baseline = pickle.load(f)\n","    \n","    X_train_baseline = train_baseline[X_feature_baseline]\n","    y_train_baseline = train_baseline[y_feature]\n","\n","    X_val_baseline = val_baseline[X_feature_baseline]\n","    y_val_baseline = val_baseline[y_feature]\n","\n","    #Standardize the dataset\n","    scaler = preprocessing.StandardScaler()\n","    # fit and transform data\n","    scaler.fit(X_train_baseline)\n","    X_train_baseline = scaler.transform(X_train_baseline)\n","    X_val_baseline = scaler.transform(X_val_baseline)\n","\n","    # train a basic LR model\n","    LR_baseline = linear_model.LogisticRegression(C=10, solver='saga', max_iter=1000)\n","    LR_baseline.fit(X_train_baseline, y_train_baseline)\n","\n","    # validation of the model\n","    yhat_baseline = LR_baseline.predict(X_val_baseline)\n","    acc_baseline = np.mean(yhat_baseline == y_val_baseline)\n","    print('Baseline Dataset {}: Accuracy on the training data is {}'.format(k+1, acc_baseline))\n","\n","    # plot graph of feature importances for better visualization\n","    feat_importances = LR_baseline.coef_.ravel()\n","    feat_importances = pd.Series(feat_importances, index=X_feature_baseline)\n","    feat_importances.nlargest(len(X_feature_baseline)).plot(kind='barh')\n","    plt.savefig('./figs/feature_importance_baseline_{}.pdf'.format(k+1))\n","    plt.clf()\n","\n","\n","    # Interprete the Weight Vector for features\n","    W_baseline = LR_baseline.coef_.ravel()\n","    ind = np.argsort(np.abs(W_baseline))\n","    for j in range(1,len(ind)):\n","        i = ind[-j]\n","        name = X_feature_baseline[i]\n","        print('The {0:d} most significant feature is {1:s}'.format(j, name))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Results:"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# 9 most important features + 2 extra vital sign features\n","X_feature_baseline_fs = ['HR', 'SaO2', 'PH', 'DBP', 'RR', 'BUN', 'MAP', 'Glucose', 'WBC', 'Temp', 'SBP']\n","\n","y_feature = 'sepsis'"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Engineered Data"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1666645625463,"user":{"displayName":"Jinyi Jin","userId":"06348382445328590699"},"user_tz":-120},"id":"9agQWxbKmBZB"},"outputs":[],"source":["\n","\n","X_feature_engineered = ['HR', 'SaO2', 'Temp', 'SBP', 'MAP', 'DBP', 'RR', 'BaseExcess', 'HCO3',\n","       'PH', 'BUN', 'Calcium', 'Chloride', 'Creatinine', 'Glucose', 'Lactic',\n","       'Magnesium', 'Potassium', 'PTT', 'WBC', 'Platelet', 'age', 'gender',\n","       'HR_dev_1', 'HR_dev_2', 'HR_dev_3', 'RR_dev_1',\n","       'RR_dev_2', 'RR_dev_3', 'Temp_dev_1', 'Temp_dev_2', 'Temp_dev_3',\n","       'Bradycardia', 'Tachycardia', 'Hypothermia', 'Fever', 'Hyperpyrexia']\n","\n","y_feature = 'sepsis'\n","# omit the patient_id here"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1666645628514,"user":{"displayName":"Jinyi Jin","userId":"06348382445328590699"},"user_tz":-120},"id":"zm0Xu8q-soRK","outputId":"5bd375df-1343-413d-df7d-5fc409383d14"},"outputs":[{"name":"stdout","output_type":"stream","text":["There are  37 Features inside engineered data with subject_id and sepsis excluded\n"]}],"source":["max_features_eng = len(X_feature_engineered)\n","print('There are ',len(X_feature_engineered), 'Features inside engineered data with subject_id and sepsis excluded')"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/5 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["---Fold1/5---\n","engineered Dataset 1: Accuracy on the training data is 0.7300021109544919\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|██        | 1/5 [01:19<05:17, 79.30s/it]"]},{"name":"stdout","output_type":"stream","text":["The 1 most significant feature is HR_dev_3\n","The 2 most significant feature is Temp\n","The 3 most significant feature is HR_dev_2\n","The 4 most significant feature is Hyperpyrexia\n","The 5 most significant feature is HR_dev_1\n","The 6 most significant feature is Temp_dev_3\n","The 7 most significant feature is Temp_dev_2\n","The 8 most significant feature is Temp_dev_1\n","The 9 most significant feature is Hypothermia\n","The 10 most significant feature is Fever\n","The 11 most significant feature is SaO2\n","The 12 most significant feature is HR\n","The 13 most significant feature is PH\n","The 14 most significant feature is RR\n","The 15 most significant feature is BUN\n","The 16 most significant feature is DBP\n","The 17 most significant feature is RR_dev_1\n","The 18 most significant feature is RR_dev_2\n","The 19 most significant feature is RR_dev_3\n","The 20 most significant feature is Glucose\n","The 21 most significant feature is SBP\n","The 22 most significant feature is WBC\n","The 23 most significant feature is MAP\n","The 24 most significant feature is PTT\n","The 25 most significant feature is Platelet\n","The 26 most significant feature is Lactic\n","The 27 most significant feature is Magnesium\n","The 28 most significant feature is Bradycardia\n","The 29 most significant feature is age\n","The 30 most significant feature is gender\n","The 31 most significant feature is Calcium\n","The 32 most significant feature is HCO3\n","The 33 most significant feature is Chloride\n","The 34 most significant feature is BaseExcess\n","The 35 most significant feature is Creatinine\n","The 36 most significant feature is Potassium\n","---Fold2/5---\n","engineered Dataset 2: Accuracy on the training data is 0.7273442384880695\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|████      | 2/5 [02:50<04:19, 86.44s/it]"]},{"name":"stdout","output_type":"stream","text":["The 1 most significant feature is HR_dev_3\n","The 2 most significant feature is Temp\n","The 3 most significant feature is Hyperpyrexia\n","The 4 most significant feature is HR_dev_2\n","The 5 most significant feature is HR_dev_1\n","The 6 most significant feature is Hypothermia\n","The 7 most significant feature is Temp_dev_3\n","The 8 most significant feature is Temp_dev_2\n","The 9 most significant feature is Temp_dev_1\n","The 10 most significant feature is Fever\n","The 11 most significant feature is SaO2\n","The 12 most significant feature is HR\n","The 13 most significant feature is PH\n","The 14 most significant feature is RR\n","The 15 most significant feature is DBP\n","The 16 most significant feature is BUN\n","The 17 most significant feature is SBP\n","The 18 most significant feature is MAP\n","The 19 most significant feature is PTT\n","The 20 most significant feature is RR_dev_2\n","The 21 most significant feature is RR_dev_1\n","The 22 most significant feature is RR_dev_3\n","The 23 most significant feature is Lactic\n","The 24 most significant feature is Glucose\n","The 25 most significant feature is WBC\n","The 26 most significant feature is Platelet\n","The 27 most significant feature is Magnesium\n","The 28 most significant feature is Bradycardia\n","The 29 most significant feature is age\n","The 30 most significant feature is gender\n","The 31 most significant feature is Calcium\n","The 32 most significant feature is BaseExcess\n","The 33 most significant feature is Tachycardia\n","The 34 most significant feature is Creatinine\n","The 35 most significant feature is Potassium\n","The 36 most significant feature is HCO3\n","---Fold3/5---\n","engineered Dataset 3: Accuracy on the training data is 0.7325902099222485\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|██████    | 3/5 [03:51<02:29, 74.69s/it]"]},{"name":"stdout","output_type":"stream","text":["The 1 most significant feature is HR_dev_3\n","The 2 most significant feature is Temp\n","The 3 most significant feature is Hyperpyrexia\n","The 4 most significant feature is HR_dev_2\n","The 5 most significant feature is HR_dev_1\n","The 6 most significant feature is Hypothermia\n","The 7 most significant feature is Temp_dev_3\n","The 8 most significant feature is Temp_dev_2\n","The 9 most significant feature is Temp_dev_1\n","The 10 most significant feature is Fever\n","The 11 most significant feature is SaO2\n","The 12 most significant feature is HR\n","The 13 most significant feature is PH\n","The 14 most significant feature is RR\n","The 15 most significant feature is BUN\n","The 16 most significant feature is DBP\n","The 17 most significant feature is Magnesium\n","The 18 most significant feature is RR_dev_1\n","The 19 most significant feature is RR_dev_2\n","The 20 most significant feature is RR_dev_3\n","The 21 most significant feature is SBP\n","The 22 most significant feature is MAP\n","The 23 most significant feature is PTT\n","The 24 most significant feature is Platelet\n","The 25 most significant feature is WBC\n","The 26 most significant feature is Glucose\n","The 27 most significant feature is Lactic\n","The 28 most significant feature is age\n","The 29 most significant feature is HCO3\n","The 30 most significant feature is Calcium\n","The 31 most significant feature is Bradycardia\n","The 32 most significant feature is Chloride\n","The 33 most significant feature is Tachycardia\n","The 34 most significant feature is gender\n","The 35 most significant feature is Creatinine\n","The 36 most significant feature is Potassium\n","---Fold4/5---\n","engineered Dataset 4: Accuracy on the training data is 0.722188167298741\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|████████  | 4/5 [05:19<01:20, 80.09s/it]"]},{"name":"stdout","output_type":"stream","text":["The 1 most significant feature is Temp\n","The 2 most significant feature is Hyperpyrexia\n","The 3 most significant feature is HR_dev_3\n","The 4 most significant feature is HR_dev_2\n","The 5 most significant feature is Hypothermia\n","The 6 most significant feature is HR_dev_1\n","The 7 most significant feature is Temp_dev_3\n","The 8 most significant feature is Temp_dev_2\n","The 9 most significant feature is Temp_dev_1\n","The 10 most significant feature is Fever\n","The 11 most significant feature is HR\n","The 12 most significant feature is SaO2\n","The 13 most significant feature is PH\n","The 14 most significant feature is RR\n","The 15 most significant feature is DBP\n","The 16 most significant feature is BUN\n","The 17 most significant feature is MAP\n","The 18 most significant feature is SBP\n","The 19 most significant feature is PTT\n","The 20 most significant feature is RR_dev_2\n","The 21 most significant feature is RR_dev_1\n","The 22 most significant feature is RR_dev_3\n","The 23 most significant feature is WBC\n","The 24 most significant feature is Magnesium\n","The 25 most significant feature is Lactic\n","The 26 most significant feature is Glucose\n","The 27 most significant feature is Platelet\n","The 28 most significant feature is Potassium\n","The 29 most significant feature is gender\n","The 30 most significant feature is Bradycardia\n","The 31 most significant feature is Calcium\n","The 32 most significant feature is Chloride\n","The 33 most significant feature is BaseExcess\n","The 34 most significant feature is Tachycardia\n","The 35 most significant feature is HCO3\n","The 36 most significant feature is age\n","---Fold5/5---\n","engineered Dataset 5: Accuracy on the training data is 0.7348856670363754\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5/5 [06:19<00:00, 75.89s/it]"]},{"name":"stdout","output_type":"stream","text":["The 1 most significant feature is HR_dev_3\n","The 2 most significant feature is Temp\n","The 3 most significant feature is Hyperpyrexia\n","The 4 most significant feature is HR_dev_2\n","The 5 most significant feature is HR_dev_1\n","The 6 most significant feature is Hypothermia\n","The 7 most significant feature is Temp_dev_3\n","The 8 most significant feature is Temp_dev_2\n","The 9 most significant feature is Temp_dev_1\n","The 10 most significant feature is Fever\n","The 11 most significant feature is SaO2\n","The 12 most significant feature is HR\n","The 13 most significant feature is PH\n","The 14 most significant feature is RR\n","The 15 most significant feature is DBP\n","The 16 most significant feature is BUN\n","The 17 most significant feature is MAP\n","The 18 most significant feature is WBC\n","The 19 most significant feature is Glucose\n","The 20 most significant feature is PTT\n","The 21 most significant feature is SBP\n","The 22 most significant feature is RR_dev_2\n","The 23 most significant feature is RR_dev_1\n","The 24 most significant feature is RR_dev_3\n","The 25 most significant feature is Platelet\n","The 26 most significant feature is Lactic\n","The 27 most significant feature is Bradycardia\n","The 28 most significant feature is Magnesium\n","The 29 most significant feature is age\n","The 30 most significant feature is Calcium\n","The 31 most significant feature is gender\n","The 32 most significant feature is Chloride\n","The 33 most significant feature is HCO3\n","The 34 most significant feature is Potassium\n","The 35 most significant feature is Tachycardia\n","The 36 most significant feature is BaseExcess\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# In Random Forest model, the data split in 5-fold crossvalidation is stored,\n","# It can be directly applied here\n","\n","for k in tqdm(range(5)):\n","\n","    print('---Fold{}/5---'.format(k+1))\n","\n","    # load the train and val data\n","    filename = '../data/data_both/kFold_engineered/fold{}/train.pickle'.format(k+1)\n","    with open(filename, 'rb') as f:\n","        train_engineered = pickle.load(f)\n","\n","    filename = '../data/data_both/kFold_engineered/fold{}/val.pickle'.format(k+1)\n","    with open(filename, 'rb') as f:\n","        val_engineered = pickle.load(f)\n","    \n","    X_train_engineered = train_engineered[X_feature_engineered]\n","    y_train_engineered = train_engineered[y_feature]\n","\n","    X_val_engineered = val_engineered[X_feature_engineered]\n","    y_val_engineered = val_engineered[y_feature]\n","\n","    #Standardize the dataset\n","    scaler = preprocessing.StandardScaler()\n","    # fit and transform data\n","    scaler.fit(X_train_engineered)\n","    X_train_engineered = scaler.transform(X_train_engineered)\n","    X_val_engineered = scaler.transform(X_val_engineered)\n","\n","    # train a basic LR model\n","    LR_engineered = linear_model.LogisticRegression(C=10, solver='saga', max_iter=1000)\n","    LR_engineered.fit(X_train_engineered, y_train_engineered)\n","\n","    # validation of the model\n","    yhat_engineered = LR_engineered.predict(X_val_engineered)\n","    acc_engineered = np.mean(yhat_engineered == y_val_engineered)\n","    print('engineered Dataset {}: Accuracy on the training data is {}'.format(k+1, acc_engineered))\n","\n","    # plot graph of feature importances for better visualization\n","    feat_importances = LR_engineered.coef_.ravel()\n","    feat_importances = pd.Series(feat_importances, index=X_feature_engineered)\n","    feat_importances.nlargest(len(X_feature_engineered)).plot(kind='barh')\n","    plt.savefig('./figs/feature_importance_engineered_{}.pdf'.format(k+1))\n","    plt.clf()\n","\n","\n","    # Interprete the Weight Vector for features\n","    W_engineered = LR_engineered.coef_.ravel()\n","    ind = np.argsort(np.abs(W_engineered))\n","    for j in range(1,len(ind)):\n","        i = ind[-j]\n","        name = X_feature_engineered[i]\n","        print('The {0:d} most significant feature is {1:s}'.format(j, name))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Results:"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# 18 most important features + 1 extra vital sign features\n","X_feature_engineered_fs = ['HR_dev_3', 'Temp', 'Hyperpyrexia', 'HR_dev_2', 'HR_dev_1', 'Hypothermia', 'Temp_dev_3',\n","                            'Temp_dev_2', 'Temp_dev_1', 'Fever', 'SaO2', 'HR', 'PH', 'RR', 'DBP', 'BUN', 'MAP', 'WBC', 'SBP']\n","\n","y_feature = 'sepsis'"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Hyper-parameter Tuning"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Baseline Data without Feature Selection"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# In Random Forest model, the data split in 5-fold crossvalidation is stored,\n","# It can be directly applied here\n","\n","for k in tqdm(range(5)):\n","\n","    print('---Fold{}/5---'.format(k+1))\n","\n","    # load the train and val data\n","    filename = '../data/data_both/kFold_baseline/fold{}/train.pickle'.format(k+1)\n","    with open(filename, 'rb') as f:\n","        train_baseline = pickle.load(f)\n","\n","    filename = '../data/data_both/kFold_baseline/fold{}/val.pickle'.format(k+1)\n","    with open(filename, 'rb') as f:\n","        val_baseline = pickle.load(f)\n","    \n","    X_train_baseline = train_baseline[X_feature_baseline]\n","    y_train_baseline = train_baseline[y_feature]\n","\n","    X_val_baseline = val_baseline[X_feature_baseline]\n","    y_val_baseline = val_baseline[y_feature]\n","\n","    #Standardize the dataset\n","    scaler = preprocessing.StandardScaler()\n","    # fit and transform data\n","    scaler.fit(X_train_baseline)\n","    X_train_baseline = scaler.transform(X_train_baseline)\n","    X_val_baseline = scaler.transform(X_val_baseline)\n","\n","    # create a logistic regression model\n","    model_baseline = linear_model.LogisticRegression(solver='saga', max_iter=1000)\n","\n","    # create hyperparameter search space\n","    # create regularization penalty space\n","    penalty = ['l1', 'l2']\n","    # create regularization hyperparameter space\n","    C = np.logspace(-1, 4, 10)  #from 10e-1 to 10e4, evenly pick 10 number\n","    # create hyperparameter options\n","    hyperparameters = dict(C=C, penalty=penalty)\n","\n","    #Grid search for best parameters\n","    clf = GridSearchCV(model_baseline, hyperparameters, verbose=2, scoring='accuracy')\n","    best_model = clf.fit(X_train_baseline, y_train_baseline)\n","    print('Best Parameters: ', best_model.best_params_)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Results:\n","\n","Best Parameters:  {'C': 0.1, 'penalty': 'l1'}"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Baseline Data with Feature Selection"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# In Random Forest model, the data split in 5-fold crossvalidation is stored,\n","# It can be directly applied here\n","\n","for k in tqdm(range(5)):\n","\n","    print('---Fold{}/5---'.format(k+1))\n","\n","    # load the train and val data\n","    filename = '../data/data_both/kFold_baseline/fold{}/train.pickle'.format(k+1)\n","    with open(filename, 'rb') as f:\n","        train_baseline = pickle.load(f)\n","\n","    filename = '../data/data_both/kFold_baseline/fold{}/val.pickle'.format(k+1)\n","    with open(filename, 'rb') as f:\n","        val_baseline = pickle.load(f)\n","    \n","    X_train_baseline = train_baseline[X_feature_baseline_fs]\n","    y_train_baseline = train_baseline[y_feature]\n","\n","    X_val_baseline = val_baseline[X_feature_baseline_fs]\n","    y_val_baseline = val_baseline[y_feature]\n","\n","    #Standardize the dataset\n","    scaler = preprocessing.StandardScaler()\n","    # fit and transform data\n","    scaler.fit(X_train_baseline)\n","    X_train_baseline = scaler.transform(X_train_baseline)\n","    X_val_baseline = scaler.transform(X_val_baseline)\n","\n","    # create a logistic regression model\n","    model_baseline = linear_model.LogisticRegression(solver='saga', max_iter=1000)\n","\n","    # create hyperparameter search space\n","    # create regularization penalty space\n","    penalty = ['l1', 'l2']\n","    # create regularization hyperparameter space\n","    C = np.logspace(-1, 4, 10)  #from 10e-1 to 10e4, evenly pick 10 number\n","    # create hyperparameter options\n","    hyperparameters = dict(C=C, penalty=penalty)\n","\n","    #Grid search for best parameters\n","    clf = GridSearchCV(model_baseline, hyperparameters, verbose=2, scoring='accuracy')\n","    best_model = clf.fit(X_train_baseline, y_train_baseline)\n","    print('Best Parameters: ', best_model.best_params_)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Results:\n","\n","Best Parameters:  {'C': 0.1, 'penalty': 'l1'}"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Engineered Data without Feature Engineering"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# In Random Forest model, the data split in 5-fold crossvalidation is stored,\n","# It can be directly applied here\n","\n","for k in tqdm(range(5)):\n","\n","    print('---Fold{}/5---'.format(k+1))\n","\n","    # load the train and val data\n","    filename = '../data/data_both/kFold_engineered/fold{}/train.pickle'.format(k+1)\n","    with open(filename, 'rb') as f:\n","        train_engineered = pickle.load(f)\n","\n","    filename = '../data/data_both/kFold_engineered/fold{}/val.pickle'.format(k+1)\n","    with open(filename, 'rb') as f:\n","        val_engineered = pickle.load(f)\n","    \n","    X_train_engineered = train_engineered[X_feature_engineered]\n","    y_train_engineered = train_engineered[y_feature]\n","\n","    X_val_engineered = val_engineered[X_feature_engineered]\n","    y_val_engineered = val_engineered[y_feature]\n","\n","    #Standardize the dataset\n","    scaler = preprocessing.StandardScaler()\n","    # fit and transform data\n","    scaler.fit(X_train_engineered)\n","    X_train_engineered = scaler.transform(X_train_engineered)\n","    X_val_engineered = scaler.transform(X_val_engineered)\n","\n","    # create a logistic regression model\n","    model_engineered = linear_model.LogisticRegression(solver='saga', max_iter=1000)\n","\n","    # create hyperparameter search space\n","    # create regularization penalty space\n","    penalty = ['l1', 'l2']\n","    # create regularization hyperparameter space\n","    C = np.logspace(-1, 4, 10)  #from 10e-1 to 10e4, evenly pick 10 number\n","    # create hyperparameter options\n","    hyperparameters = dict(C=C, penalty=penalty)\n","\n","    #Grid search for best parameters\n","    clf = GridSearchCV(model_engineered, hyperparameters, verbose=2, n_jobs = -1, scoring='accuracy')\n","    best_model = clf.fit(X_train_engineered, y_train_engineered)\n","    print('Best Parameters: ', best_model.best_params_)\n","\n","    "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Results:\n","\n","Best Parameters:  {'C': 4.641588833612779, 'penalty': 'l2'}"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Engineered Data with Feature Engineering"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# In Random Forest model, the data split in 5-fold crossvalidation is stored,\n","# It can be directly applied here\n","\n","for k in tqdm(range(5)):\n","\n","    print('---Fold{}/5---'.format(k+1))\n","\n","    # load the train and val data\n","    filename = '../data/data_both/kFold_engineered/fold{}/train.pickle'.format(k+1)\n","    with open(filename, 'rb') as f:\n","        train_engineered = pickle.load(f)\n","\n","    filename = '../data/data_both/kFold_engineered/fold{}/val.pickle'.format(k+1)\n","    with open(filename, 'rb') as f:\n","        val_engineered = pickle.load(f)\n","    \n","    X_train_engineered = train_engineered[X_feature_engineered_fs]\n","    y_train_engineered = train_engineered[y_feature]\n","\n","    X_val_engineered = val_engineered[X_feature_engineered_fs]\n","    y_val_engineered = val_engineered[y_feature]\n","\n","    #Standardize the dataset\n","    scaler = preprocessing.StandardScaler()\n","    # fit and transform data\n","    scaler.fit(X_train_engineered)\n","    X_train_engineered = scaler.transform(X_train_engineered)\n","    X_val_engineered = scaler.transform(X_val_engineered)\n","\n","    # create a logistic regression model\n","    model_engineered = linear_model.LogisticRegression(solver='saga', max_iter=1000)\n","\n","    # create hyperparameter search space\n","    # create regularization penalty space\n","    penalty = ['l1', 'l2']\n","    # create regularization hyperparameter space\n","    C = np.logspace(-1, 4, 10)\n","    # create hyperparameter options\n","    hyperparameters = dict(C=C, penalty=penalty)\n","\n","    #Grid search for best parameters\n","    clf = GridSearchCV(model_engineered, hyperparameters, verbose=2, n_jobs = -1, scoring='accuracy')\n","    best_model = clf.fit(X_train_engineered, y_train_engineered)\n","    print('Best Parameters: ', best_model.best_params_)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Results:\n","\n","Best Parameters:  {'C': 0.35938136638046275, 'penalty': 'l2'}"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Re-train Model with Optimized Params"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["!mkdir -p ./trained_models/BDWOFS\n","!mkdir -p ./trained_models/BDWFS\n","!mkdir -p ./trained_models/EDWOFS\n","!mkdir -p ./trained_models/EDWFS"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Baseline Data without Feature Selection"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/5 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["---Fold1/5---\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.61      0.56      0.59     72765\n","           1       0.60      0.65      0.63     74088\n","\n","    accuracy                           0.61    146853\n","   macro avg       0.61      0.61      0.61    146853\n","weighted avg       0.61      0.61      0.61    146853\n","\n","F1 score: 0.6252623780713669\n","Accuracy: 0.6073284168522264\n","AUPRC: 0.6282841201768549\n","AUROC: 0.6466492202990883\n","AUROC threshold: [1.97742877 0.97742877 0.97258831 ... 0.08067428 0.07511855 0.07505978]\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|██        | 1/5 [00:17<01:11, 17.80s/it]"]},{"name":"stdout","output_type":"stream","text":["---Fold2/5---\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.59      0.55      0.57     74649\n","           1       0.58      0.62      0.60     74088\n","\n","    accuracy                           0.58    148737\n","   macro avg       0.58      0.58      0.58    148737\n","weighted avg       0.58      0.58      0.58    148737\n","\n","F1 score: 0.5958681249754988\n","Accuracy: 0.5841384457129026\n","AUPRC: 0.6018530705842269\n","AUROC: 0.6270035549114701\n","AUROC threshold: [1.91742107 0.91742107 0.90623865 ... 0.09000774 0.08983486 0.07970339]\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|████      | 2/5 [00:37<00:56, 18.95s/it]"]},{"name":"stdout","output_type":"stream","text":["---Fold3/5---\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.60      0.58      0.59     74049\n","           1       0.60      0.62      0.61     74244\n","\n","    accuracy                           0.60    148293\n","   macro avg       0.60      0.60      0.60    148293\n","weighted avg       0.60      0.60      0.60    148293\n","\n","F1 score: 0.6059282495185531\n","Accuracy: 0.5984503651554692\n","AUPRC: 0.6215604827106587\n","AUROC: 0.6451291433072998\n","AUROC threshold: [1.90733583 0.90733583 0.88964281 ... 0.07921267 0.07796248 0.06454534]\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|██████    | 3/5 [00:53<00:34, 17.35s/it]"]},{"name":"stdout","output_type":"stream","text":["---Fold4/5---\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.61      0.56      0.59     74353\n","           1       0.59      0.65      0.62     74100\n","\n","    accuracy                           0.60    148453\n","   macro avg       0.60      0.60      0.60    148453\n","weighted avg       0.60      0.60      0.60    148453\n","\n","F1 score: 0.6191707165753283\n","Accuracy: 0.6030528180636295\n","AUPRC: 0.6212040157806212\n","AUROC: 0.6445474680878625\n","AUROC threshold: [1.91958633 0.91958633 0.91590903 ... 0.11125605 0.09620058 0.07449764]\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|████████  | 4/5 [01:10<00:17, 17.25s/it]"]},{"name":"stdout","output_type":"stream","text":["---Fold5/5---\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.60      0.56      0.58     76409\n","           1       0.58      0.62      0.60     74160\n","\n","    accuracy                           0.59    150569\n","   macro avg       0.59      0.59      0.59    150569\n","weighted avg       0.59      0.59      0.59    150569\n","\n","F1 score: 0.5995583435930508\n","Accuracy: 0.5917287090968261\n","AUPRC: 0.6039914238437414\n","AUROC: 0.6371601574324447\n","AUROC threshold: [1.97359393 0.97359393 0.97293049 ... 0.10679033 0.10314931 0.07480676]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5/5 [01:25<00:00, 17.04s/it]"]},{"name":"stdout","output_type":"stream","text":["Averaged trauining results:\n"," F1_score:0.6091575625467596\n"," Accuracy:0.5969397509762108\n"," AUROC:0.6400979088076331\n"," AUPRC:0.6153786226192206\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"data":{"text/plain":["<Figure size 1440x1440 with 0 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["<Figure size 1440x1440 with 0 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["<Figure size 1440x1440 with 0 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["<Figure size 1440x1440 with 0 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["<Figure size 1440x1440 with 0 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["f1_list = []\n","accuracy_list = []\n","auprc_list = []\n","auroc_list = []\n","\n","for k in tqdm(range(5)):\n","\n","    print('---Fold{}/5---'.format(k+1))\n","\n","    # load the train and val data\n","    filename = '../data/data_both/kFold_baseline/fold{}/train.pickle'.format(k+1)\n","    with open(filename, 'rb') as f:\n","        train_baseline = pickle.load(f)\n","\n","    filename = '../data/data_both/kFold_baseline/fold{}/val.pickle'.format(k+1)\n","    with open(filename, 'rb') as f:\n","        val_baseline = pickle.load(f)\n","    \n","    X_train_baseline = train_baseline[X_feature_baseline]\n","    y_train_baseline = train_baseline[y_feature]\n","\n","    X_val_baseline = val_baseline[X_feature_baseline]\n","    y_val_baseline = val_baseline[y_feature]\n","\n","    #Standardize the dataset\n","    scaler = preprocessing.StandardScaler()\n","    # fit and transform data\n","    scaler.fit(X_train_baseline)\n","    X_train_baseline = scaler.transform(X_train_baseline)\n","    X_val_baseline = scaler.transform(X_val_baseline)\n","\n","    # train the model using the optimized parameters\n","    model_LR = linear_model.LogisticRegression(penalty='l1', C=0.1,  solver='saga', max_iter=1000) # optimized parameters\n","    model_LR.fit(X_train_baseline, y_train_baseline)\n","    joblib.dump(model_LR, \"./trained_models/BDWOFS/model{}.joblib\".format(k+1))\n","\n","    # validation results\n","    y_pred_class = model_LR.predict(X_val_baseline)\n","    y_pred_proba = model_LR.predict_proba(X_val_baseline)[::,1]\n","    precision_, recall_, thresholds_ = precision_recall_curve(y_val_baseline, y_pred_proba)\n","    auprc_ = auc(recall_, precision_)\n","    fpr_, tpr_, thresholds_ = roc_curve(y_val_baseline, y_pred_proba)\n","    auroc_ = auc(fpr_, tpr_)\n","    f1_ = f1_score(y_val_baseline,y_pred_class)\n","    accuracy_ = accuracy_score(y_val_baseline,y_pred_class)\n","\n","    print('Classification Report:\\n', classification_report(y_val_baseline, y_pred_class))\n","    print('F1 score:', f1_)\n","    print('Accuracy:', accuracy_)\n","    print('AUPRC:', auprc_)\n","    print('AUROC:', auroc_)\n","    print('AUROC threshold:', thresholds_)\n","\n","\n","    f1_list.append(f1_)\n","    accuracy_list.append(accuracy_)\n","    auprc_list.append(auprc_)\n","    auroc_list.append(auroc_)\n","\n","    # Plot ROC,PRC and confusion matrix\n","    bc = BinaryClassification(y_val_baseline,y_pred_proba, labels=['Non-sepsis', 'Sepsis'])\n","    plt.figure(figsize=(20,20))\n","    plt.title('Validation Results for LR using baseline data without feature selection')\n","    plt.subplot2grid(shape=(2,4), loc=(0,0), colspan=2)\n","    bc.plot_roc_curve()\n","    plt.subplot2grid((2,4), (0,2), colspan=2)\n","    bc.plot_precision_recall_curve()\n","    plt.subplot2grid((2,4), (1,0), colspan=2)\n","    bc.plot_confusion_matrix()\n","    plt.subplot2grid((2,4), (1,2), colspan=2)\n","    bc.plot_confusion_matrix(normalize=True)\n","    plt.savefig('./figs/val_wo_fs_baseline_{}.pdf'.format(k+1))\n","    plt.clf()\n","\n","def Average(lst):\n","    return sum(lst) / len(lst)\n","\n","print('Averaged trauining results:\\n F1_score:{}\\n Accuracy:{}\\n AUROC:{}\\n AUPRC:{}\\n'.format(Average(f1_list),Average(accuracy_list), Average(auroc_list), Average(auprc_list)))\n","\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Baseline Data with Feature Selection"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/5 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["---Fold1/5---\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.61      0.55      0.58     72765\n","           1       0.60      0.65      0.62     74088\n","\n","    accuracy                           0.60    146853\n","   macro avg       0.60      0.60      0.60    146853\n","weighted avg       0.60      0.60      0.60    146853\n","\n","F1 score: 0.6240852575488455\n","Accuracy: 0.6036785084404132\n","AUPRC: 0.6291044573430182\n","AUROC: 0.6452264603197085\n","AUROC threshold: [1.92295411 0.92295411 0.91545219 ... 0.09132688 0.07664526 0.07651829]\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|██        | 1/5 [00:10<00:43, 10.76s/it]"]},{"name":"stdout","output_type":"stream","text":["---Fold2/5---\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.59      0.55      0.57     74649\n","           1       0.57      0.61      0.59     74088\n","\n","    accuracy                           0.58    148737\n","   macro avg       0.58      0.58      0.58    148737\n","weighted avg       0.58      0.58      0.58    148737\n","\n","F1 score: 0.5938192723953579\n","Accuracy: 0.5811398643242771\n","AUPRC: 0.6039768769569549\n","AUROC: 0.626133384902178\n","AUROC threshold: [1.91203787 0.91203787 0.89763862 ... 0.11112851 0.10834538 0.0788769 ]\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|████      | 2/5 [00:21<00:33, 11.02s/it]"]},{"name":"stdout","output_type":"stream","text":["---Fold3/5---\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.60      0.57      0.59     74049\n","           1       0.59      0.63      0.61     74244\n","\n","    accuracy                           0.60    148293\n","   macro avg       0.60      0.60      0.60    148293\n","weighted avg       0.60      0.60      0.60    148293\n","\n","F1 score: 0.611146751155392\n","Accuracy: 0.599428159117423\n","AUPRC: 0.6209295940103094\n","AUROC: 0.6444836217434581\n","AUROC threshold: [1.90358228 0.90358228 0.87495849 ... 0.08517733 0.07947758 0.07687931]\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|██████    | 3/5 [00:34<00:23, 11.59s/it]"]},{"name":"stdout","output_type":"stream","text":["---Fold4/5---\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.62      0.55      0.58     74353\n","           1       0.59      0.66      0.62     74100\n","\n","    accuracy                           0.60    148453\n","   macro avg       0.61      0.60      0.60    148453\n","weighted avg       0.61      0.60      0.60    148453\n","\n","F1 score: 0.623735934367855\n","Accuracy: 0.6042451146154002\n","AUPRC: 0.6216538004396014\n","AUROC: 0.6438094773966685\n","AUROC threshold: [1.91033539 0.91033539 0.90739824 ... 0.11395172 0.09307753 0.08363404]\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|████████  | 4/5 [00:46<00:11, 11.77s/it]"]},{"name":"stdout","output_type":"stream","text":["---Fold5/5---\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.61      0.56      0.58     76409\n","           1       0.58      0.62      0.60     74160\n","\n","    accuracy                           0.59    150569\n","   macro avg       0.59      0.59      0.59    150569\n","weighted avg       0.59      0.59      0.59    150569\n","\n","F1 score: 0.6013766924281917\n","Accuracy: 0.5926983642051152\n","AUPRC: 0.6089811420729806\n","AUROC: 0.6375620600955147\n","AUROC threshold: [1.9782738  0.9782738  0.97772784 ... 0.10322481 0.09946816 0.07871643]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5/5 [00:57<00:00, 11.59s/it]"]},{"name":"stdout","output_type":"stream","text":["Averaged trauining results:\n"," F1_score:0.6108327815791285\n"," Accuracy:0.5962380021405258\n"," AUROC:0.6394430008915056\n"," AUPRC:0.6169291741645729\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"data":{"text/plain":["<Figure size 1440x1440 with 0 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["<Figure size 1440x1440 with 0 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["<Figure size 1440x1440 with 0 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["<Figure size 1440x1440 with 0 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["<Figure size 1440x1440 with 0 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["f1_list = []\n","accuracy_list = []\n","auprc_list = []\n","auroc_list = []\n","\n","for k in tqdm(range(5)):\n","\n","    print('---Fold{}/5---'.format(k+1))\n","\n","    # load the train and val data\n","    filename = '../data/data_both/kFold_baseline/fold{}/train.pickle'.format(k+1)\n","    with open(filename, 'rb') as f:\n","        train_baseline = pickle.load(f)\n","\n","    filename = '../data/data_both/kFold_baseline/fold{}/val.pickle'.format(k+1)\n","    with open(filename, 'rb') as f:\n","        val_baseline = pickle.load(f)\n","    \n","    X_train_baseline = train_baseline[X_feature_baseline_fs]\n","    y_train_baseline = train_baseline[y_feature]\n","\n","    X_val_baseline = val_baseline[X_feature_baseline_fs]\n","    y_val_baseline = val_baseline[y_feature]\n","\n","    #Standardize the dataset\n","    scaler = preprocessing.StandardScaler()\n","    # fit and transform data\n","    scaler.fit(X_train_baseline)\n","    X_train_baseline = scaler.transform(X_train_baseline)\n","    X_val_baseline = scaler.transform(X_val_baseline)\n","\n","    # train the model using the optimized parameters\n","    model_LR = linear_model.LogisticRegression(penalty='l1', C=0.1,  solver='saga', max_iter=1000) # optimized parameters\n","    model_LR.fit(X_train_baseline, y_train_baseline)\n","    joblib.dump(model_LR, \"./trained_models/BDWFS/model{}.joblib\".format(k+1))\n","\n","    # validation results\n","    y_pred_class = model_LR.predict(X_val_baseline)\n","    y_pred_proba = model_LR.predict_proba(X_val_baseline)[::,1]\n","    precision_, recall_, thresholds_ = precision_recall_curve(y_val_baseline, y_pred_proba)\n","    auprc_ = auc(recall_, precision_)\n","    fpr_, tpr_, thresholds_ = roc_curve(y_val_baseline, y_pred_proba)\n","    auroc_ = auc(fpr_, tpr_)\n","    f1_ = f1_score(y_val_baseline,y_pred_class)\n","    accuracy_ = accuracy_score(y_val_baseline,y_pred_class)\n","\n","    print('Classification Report:\\n', classification_report(y_val_baseline, y_pred_class))\n","    print('F1 score:', f1_)\n","    print('Accuracy:', accuracy_)\n","    print('AUPRC:', auprc_)\n","    print('AUROC:', auroc_)\n","    print('AUROC threshold:', thresholds_)\n","\n","\n","    f1_list.append(f1_)\n","    accuracy_list.append(accuracy_)\n","    auprc_list.append(auprc_)\n","    auroc_list.append(auroc_)\n","\n","    # Plot ROC,PRC and confusion matrix\n","    bc = BinaryClassification(y_val_baseline,y_pred_proba, labels=['Non-sepsis', 'Sepsis'])\n","    plt.figure(figsize=(20,20))\n","    plt.subplot2grid(shape=(2,4), loc=(0,0), colspan=2)\n","    bc.plot_roc_curve()\n","    plt.subplot2grid((2,4), (0,2), colspan=2)\n","    bc.plot_precision_recall_curve()\n","    plt.subplot2grid((2,4), (1,0), colspan=2)\n","    bc.plot_confusion_matrix()\n","    plt.subplot2grid((2,4), (1,2), colspan=2)\n","    bc.plot_confusion_matrix(normalize=True)\n","    plt.title('Validation Results for LR using baseline data with feature selection')\n","    plt.savefig('./figs/val_w_fs_baseline_{}.pdf'.format(k+1))\n","    plt.clf()\n","\n","def Average(lst):\n","    return sum(lst) / len(lst)\n","\n","print('Averaged trauining results:\\n F1_score:{}\\n Accuracy:{}\\n AUROC:{}\\n AUPRC:{}\\n'.format(Average(f1_list),Average(accuracy_list), Average(auroc_list), Average(auprc_list)))\n","\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Engineered Data without Feature Selection"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/5 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["---Fold1/5---\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.75      0.69      0.72     72765\n","           1       0.72      0.77      0.74     74088\n","\n","    accuracy                           0.73    146853\n","   macro avg       0.73      0.73      0.73    146853\n","weighted avg       0.73      0.73      0.73    146853\n","\n","F1 score: 0.7423082422367513\n","Accuracy: 0.7300021109544919\n","AUPRC: 0.7604508823451716\n","AUROC: 0.7966710722206118\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|██        | 1/5 [01:16<05:04, 76.19s/it]"]},{"name":"stdout","output_type":"stream","text":["---Fold2/5---\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.75      0.69      0.72     74649\n","           1       0.71      0.76      0.74     74088\n","\n","    accuracy                           0.73    148737\n","   macro avg       0.73      0.73      0.73    148737\n","weighted avg       0.73      0.73      0.73    148737\n","\n","F1 score: 0.7362135581313665\n","Accuracy: 0.7273442384880695\n","AUPRC: 0.748809780899778\n","AUROC: 0.7918460533293871\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|████      | 2/5 [02:40<04:02, 80.71s/it]"]},{"name":"stdout","output_type":"stream","text":["---Fold3/5---\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.74      0.72      0.73     74049\n","           1       0.73      0.75      0.74     74244\n","\n","    accuracy                           0.73    148293\n","   macro avg       0.73      0.73      0.73    148293\n","weighted avg       0.73      0.73      0.73    148293\n","\n","F1 score: 0.737112855324565\n","Accuracy: 0.7325834665156143\n","AUPRC: 0.7585649179716827\n","AUROC: 0.7953656469414427\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|██████    | 3/5 [03:48<02:30, 75.06s/it]"]},{"name":"stdout","output_type":"stream","text":["---Fold4/5---\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.74      0.69      0.71     74353\n","           1       0.71      0.76      0.73     74100\n","\n","    accuracy                           0.72    148453\n","   macro avg       0.72      0.72      0.72    148453\n","weighted avg       0.72      0.72      0.72    148453\n","\n","F1 score: 0.7311788707974294\n","Accuracy: 0.722188167298741\n","AUPRC: 0.7674352451497981\n","AUROC: 0.795848082385857\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|████████  | 4/5 [05:24<01:23, 83.27s/it]"]},{"name":"stdout","output_type":"stream","text":["---Fold5/5---\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.75      0.71      0.73     76409\n","           1       0.72      0.76      0.74     74160\n","\n","    accuracy                           0.73    150569\n","   macro avg       0.74      0.74      0.73    150569\n","weighted avg       0.74      0.73      0.73    150569\n","\n","F1 score: 0.7385340931420712\n","Accuracy: 0.7348856670363754\n","AUPRC: 0.7534872843549885\n","AUROC: 0.7969632923331479\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5/5 [06:32<00:00, 78.58s/it]"]},{"name":"stdout","output_type":"stream","text":["Averaged trauining results:\n"," F1_score:0.7370695239264368\n"," Accuracy:0.7294007300586585\n"," AUROC:0.7953388294420892\n"," AUPRC:0.7577496221442838\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"data":{"text/plain":["<Figure size 1440x1440 with 0 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["<Figure size 1440x1440 with 0 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["<Figure size 1440x1440 with 0 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["<Figure size 1440x1440 with 0 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["<Figure size 1440x1440 with 0 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["f1_list = []\n","accuracy_list = []\n","auprc_list = []\n","auroc_list = []\n","\n","for k in tqdm(range(5)):\n","\n","    print('---Fold{}/5---'.format(k+1))\n","\n","    # load the train and val data\n","    filename = '../data/data_both/kFold_engineered/fold{}/train.pickle'.format(k+1)\n","    with open(filename, 'rb') as f:\n","        train_engineered = pickle.load(f)\n","\n","    filename = '../data/data_both/kFold_engineered/fold{}/val.pickle'.format(k+1)\n","    with open(filename, 'rb') as f:\n","        val_engineered = pickle.load(f)\n","    \n","    X_train_engineered = train_engineered[X_feature_engineered]\n","    y_train_engineered = train_engineered[y_feature]\n","\n","    X_val_engineered = val_engineered[X_feature_engineered]\n","    y_val_engineered = val_engineered[y_feature]\n","\n","    #Standardize the dataset\n","    scaler = preprocessing.StandardScaler()\n","    # fit and transform data\n","    scaler.fit(X_train_engineered)\n","    X_train_engineered = scaler.transform(X_train_engineered)\n","    X_val_engineered = scaler.transform(X_val_engineered)\n","\n","    # train the model using the optimized parameters\n","    model_LR = linear_model.LogisticRegression(penalty='l2', C=4.642,  solver='saga', max_iter=1000) # optimized parameters\n","    model_LR.fit(X_train_engineered, y_train_engineered)\n","    joblib.dump(model_LR, \"./trained_models/EDWOFS/model{}.joblib\".format(k+1))\n","\n","    # train results\n","    y_pred_class = model_LR.predict(X_val_engineered)\n","    y_pred_proba = model_LR.predict_proba(X_val_engineered)[::,1]\n","    precision_, recall_, thresholds_ = precision_recall_curve(y_val_engineered, y_pred_proba)\n","    auprc_ = auc(recall_, precision_)\n","    fpr_, tpr_, thresholds = roc_curve(y_val_engineered, y_pred_proba)\n","    auroc_ = auc(fpr_, tpr_)\n","    f1_ = f1_score(y_val_engineered,y_pred_class)\n","    accuracy_ = accuracy_score(y_val_engineered,y_pred_class)\n","\n","    print('Classification Report:\\n', classification_report(y_val_engineered, y_pred_class))\n","    print('F1 score:', f1_)\n","    print('Accuracy:', accuracy_)\n","    print('AUPRC:', auprc_)\n","    print('AUROC:', auroc_)\n","\n","    f1_list.append(f1_)\n","    accuracy_list.append(accuracy_)\n","    auprc_list.append(auprc_)\n","    auroc_list.append(auroc_)\n","\n","    # Plot ROC,PRC and confusion matrix\n","    bc = BinaryClassification(y_val_engineered,y_pred_proba, labels=['Non-sepsis', 'Sepsis'])\n","    plt.figure(figsize=(20,20))\n","    plt.subplot2grid(shape=(2,4), loc=(0,0), colspan=2)\n","    bc.plot_roc_curve()\n","    plt.subplot2grid((2,4), (0,2), colspan=2)\n","    bc.plot_precision_recall_curve()\n","    plt.subplot2grid((2,4), (1,0), colspan=2)\n","    bc.plot_confusion_matrix()\n","    plt.subplot2grid((2,4), (1,2), colspan=2)\n","    bc.plot_confusion_matrix(normalize=True)\n","    plt.savefig('./figs/val_wo_fs_engineered_{}.pdf'.format(k+1))\n","    plt.clf()\n","\n","def Average(lst):\n","    return sum(lst) / len(lst)\n","\n","print('Averaged trauining results:\\n F1_score:{}\\n Accuracy:{}\\n AUROC:{}\\n AUPRC:{}\\n'.format(Average(f1_list),Average(accuracy_list), Average(auroc_list), Average(auprc_list)))\n","\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Engineered Data with Feature Selection"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/5 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["---Fold1/5---\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.76      0.67      0.71     72765\n","           1       0.71      0.79      0.75     74088\n","\n","    accuracy                           0.73    146853\n","   macro avg       0.73      0.73      0.73    146853\n","weighted avg       0.73      0.73      0.73    146853\n","\n","F1 score: 0.7484423427165543\n","Accuracy: 0.7319428271809224\n","AUPRC: 0.7506091554115969\n","AUROC: 0.7940431020860471\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|██        | 1/5 [00:40<02:43, 40.82s/it]"]},{"name":"stdout","output_type":"stream","text":["---Fold2/5---\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.74      0.67      0.70     74649\n","           1       0.70      0.76      0.73     74088\n","\n","    accuracy                           0.72    148737\n","   macro avg       0.72      0.72      0.72    148737\n","weighted avg       0.72      0.72      0.72    148737\n","\n","F1 score: 0.728613987799688\n","Accuracy: 0.7170441786509073\n","AUPRC: 0.7345815733471153\n","AUROC: 0.7817493438669931\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|████      | 2/5 [01:27<02:12, 44.16s/it]"]},{"name":"stdout","output_type":"stream","text":["---Fold3/5---\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.74      0.70      0.72     74049\n","           1       0.72      0.75      0.73     74244\n","\n","    accuracy                           0.73    148293\n","   macro avg       0.73      0.73      0.73    148293\n","weighted avg       0.73      0.73      0.73    148293\n","\n","F1 score: 0.7330268531854862\n","Accuracy: 0.7262648944994032\n","AUPRC: 0.7449627792393205\n","AUROC: 0.7905162693272336\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|██████    | 3/5 [02:08<01:25, 42.86s/it]"]},{"name":"stdout","output_type":"stream","text":["---Fold4/5---\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.75      0.68      0.71     74353\n","           1       0.70      0.77      0.73     74100\n","\n","    accuracy                           0.72    148453\n","   macro avg       0.72      0.72      0.72    148453\n","weighted avg       0.72      0.72      0.72    148453\n","\n","F1 score: 0.7345264054294672\n","Accuracy: 0.7228078920601133\n","AUPRC: 0.7535840144088678\n","AUROC: 0.790079525990228\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|████████  | 4/5 [03:11<00:50, 50.90s/it]"]},{"name":"stdout","output_type":"stream","text":["---Fold5/5---\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.74      0.69      0.72     76409\n","           1       0.70      0.76      0.73     74160\n","\n","    accuracy                           0.72    150569\n","   macro avg       0.72      0.72      0.72    150569\n","weighted avg       0.72      0.72      0.72    150569\n","\n","F1 score: 0.7287386215864758\n","Accuracy: 0.7229177320696824\n","AUPRC: 0.7423721936921293\n","AUROC: 0.7900242461144528\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5/5 [04:08<00:00, 49.76s/it]"]},{"name":"stdout","output_type":"stream","text":["Averaged trauining results:\n"," F1_score:0.7346696421435344\n"," Accuracy:0.7241955048922057\n"," AUROC:0.789282497476991\n"," AUPRC:0.745221943219806\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"data":{"text/plain":["<Figure size 1440x1440 with 0 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["<Figure size 1440x1440 with 0 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["<Figure size 1440x1440 with 0 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["<Figure size 1440x1440 with 0 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["<Figure size 1440x1440 with 0 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["f1_list = []\n","accuracy_list = []\n","auprc_list = []\n","auroc_list = []\n","\n","for k in tqdm(range(5)):\n","\n","    print('---Fold{}/5---'.format(k+1))\n","\n","    # load the train and val data\n","    filename = '../data/data_both/kFold_engineered/fold{}/train.pickle'.format(k+1)\n","    with open(filename, 'rb') as f:\n","        train_engineered = pickle.load(f)\n","\n","    filename = '../data/data_both/kFold_engineered/fold{}/val.pickle'.format(k+1)\n","    with open(filename, 'rb') as f:\n","        val_engineered = pickle.load(f)\n","    \n","    X_train_engineered = train_engineered[X_feature_engineered_fs]\n","    y_train_engineered = train_engineered[y_feature]\n","\n","    X_val_engineered = val_engineered[X_feature_engineered_fs]\n","    y_val_engineered = val_engineered[y_feature]\n","\n","    #Standardize the dataset\n","    scaler = preprocessing.StandardScaler()\n","    # fit and transform data\n","    scaler.fit(X_train_engineered)\n","    X_train_engineered = scaler.transform(X_train_engineered)\n","    X_val_engineered = scaler.transform(X_val_engineered)\n","\n","    # train the model using the optimized parameters\n","    model_LR = linear_model.LogisticRegression(penalty='l2', C=0.359,  solver='saga', max_iter=1000) # optimized parameters\n","    model_LR.fit(X_train_engineered, y_train_engineered)\n","    joblib.dump(model_LR, \"./trained_models/EDWFS/model{}.joblib\".format(k+1))\n","\n","    # train results\n","    y_pred_class = model_LR.predict(X_val_engineered)\n","    y_pred_proba = model_LR.predict_proba(X_val_engineered)[::,1]\n","    precision_, recall_, thresholds_ = precision_recall_curve(y_val_engineered, y_pred_proba)\n","    auprc_ = auc(recall_, precision_)\n","    fpr_, tpr_, thresholds = roc_curve(y_val_engineered, y_pred_proba)\n","    auroc_ = auc(fpr_, tpr_)\n","    f1_ = f1_score(y_val_engineered,y_pred_class)\n","    accuracy_ = accuracy_score(y_val_engineered,y_pred_class)\n","\n","    print('Classification Report:\\n', classification_report(y_val_engineered, y_pred_class))\n","    print('F1 score:', f1_)\n","    print('Accuracy:', accuracy_)\n","    print('AUPRC:', auprc_)\n","    print('AUROC:', auroc_)\n","\n","    f1_list.append(f1_)\n","    accuracy_list.append(accuracy_)\n","    auprc_list.append(auprc_)\n","    auroc_list.append(auroc_)\n","\n","    # Plot ROC,PRC and confusion matrix\n","    bc = BinaryClassification(y_val_engineered,y_pred_proba, labels=['Non-sepsis', 'Sepsis'])\n","    plt.figure(figsize=(20,20))\n","    plt.subplot2grid(shape=(2,4), loc=(0,0), colspan=2)\n","    bc.plot_roc_curve()\n","    plt.subplot2grid((2,4), (0,2), colspan=2)\n","    bc.plot_precision_recall_curve()\n","    plt.subplot2grid((2,4), (1,0), colspan=2)\n","    bc.plot_confusion_matrix()\n","    plt.subplot2grid((2,4), (1,2), colspan=2)\n","    bc.plot_confusion_matrix(normalize=True)\n","    plt.savefig('./figs/val_w_fs_engineered_{}.pdf'.format(k+1))\n","    plt.clf()\n","\n","def Average(lst):\n","    return sum(lst) / len(lst)\n","\n","print('Averaged trauining results:\\n F1_score:{}\\n Accuracy:{}\\n AUROC:{}\\n AUPRC:{}\\n'.format(Average(f1_list),Average(accuracy_list), Average(auroc_list), Average(auprc_list)))\n","\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"9XoESScg6ycI"},"source":["## Performance on Test Data"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Helper Functions"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def save_challenge_predictions(file, scores, labels):\n","    with open(file, 'w') as f:\n","        f.write('PredictedProbability,PredictedLabel\\n')\n","        for (s, l) in zip(scores, labels):\n","            f.write('%g,%d\\n' % (s, l))\n","\n","def save_challenge_testlabel(file, labels):\n","    with open(file, 'w') as f:\n","        f.write('sepsis\\n')\n","        for l in labels:\n","            f.write('%d\\n' % l)\n","\n","def load_model_predict(X_test, k_fold, path):\n","    \"ensemble the five LR  models by averaging their output probabilities\"\n","    test_pred = np.zeros((X_test.shape[0], k_fold))\n","    for k in range(k_fold):\n","        # load the model\n","        model_path_name = path + 'model{}.joblib'.format(k+1)\n","        loaded_model = joblib.load(model_path_name)\n","        #Standardize the dataset\n","        scaler = preprocessing.StandardScaler()\n","        # fit and transform data\n","        scaler.fit(X_test)\n","        X_test = scaler.transform(X_test)\n","        # predict\n","        y_test_pred = loaded_model.predict_proba(X_test)[::,1]\n","        test_pred[:, k] = y_test_pred # save prediction results 5 times\n","    test_pred = pd.DataFrame(test_pred)\n","    result_pro = test_pred.mean(axis=1)\n","\n","    return result_pro\n","\n","def feature_extraction(case, data_features):\n","    labels = np.array(case['sepsis'])\n","    features = case[data_features]\n","    if 'time' in features.columns:\n","        features = features.drop(columns=['time'],axis = 1)\n","\n","    return  features, labels    \n","\n","def predict(data_set,\n","            data_dir,\n","            save_prediction_dir,\n","            save_label_dir,\n","            model_path,\n","            risk_threshold,\n","            data_features\n","            ):\n","    for csv in tqdm(data_set):\n","        csv = csv.replace('psv','csv')\n","        patient = pd.read_csv(data_dir+csv, sep=',')\n","        features, labels = feature_extraction(patient, data_features)\n","\n","        predict_pro = load_model_predict(features, k_fold = 5, path = model_path)\n","        PredictedProbability = np.array(predict_pro)\n","        PredictedLabel = [0 if i <= risk_threshold else 1 for i in predict_pro]\n","\n","        save_prediction_name = save_prediction_dir + csv\n","        save_challenge_predictions(save_prediction_name, PredictedProbability, PredictedLabel)\n","        save_testlabel_name = save_label_dir + csv\n","        save_challenge_testlabel(save_testlabel_name, labels)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Score Functions"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# This file contains functions for evaluating algorithms for the 2019 PhysioNet/\n","# CinC Challenge. You can run it as follows:\n","\n","################################################################################\n","\n","# The evaluate_scores function computes a normalized utility score for a cohort\n","# of patients along with several traditional scoring metrics.\n","#\n","# Inputs:\n","#   'label_directory' is a directory of pipe-delimited text files containing a\n","#   binary vector of labels for whether a patient is not septic (0) or septic\n","#   (1) for each time interval.\n","#\n","#   'prediction_directory' is a directory of pipe-delimited text files, where\n","#   the first column of the file gives the predicted probability that the\n","#   patient is septic at each time, and the second column of the file is a\n","#   binarized version of this vector. Note that there must be a prediction for\n","#   every label.\n","#\n","# Outputs:\n","#   'auroc' is the area under the receiver operating characteristic curve\n","#   (AUROC).\n","#\n","#   'auprc' is the area under the precision recall curve (AUPRC).\n","#\n","#   'accuracy' is accuracy.\n","#\n","#   'f_measure' is F-measure.\n","#\n","#   'normalized_observed_utility' is a normalized utility-based measure that we\n","#   created for the Challenge. This score is normalized so that a perfect score\n","#   is 1 and no positive predictions is 0.\n","#\n","# Example:\n","#   Omitted due to length. See the below examples.\n","\n","import numpy as np, os, os.path, sys, warnings\n","\n","def evaluate_sepsis_score(label_directory, prediction_directory):\n","    # Set parameters.\n","    label_header       = 'sepsis'\n","    prediction_header  = 'PredictedLabel'\n","    probability_header = 'PredictedProbability'\n","\n","    dt_early   = -12\n","    dt_optimal = -6\n","    dt_late    = 3\n","\n","    max_u_tp = 1\n","    min_u_fn = -2\n","    u_fp     = -0.05\n","    u_tn     = 0\n","\n","    # Find label and prediction files.\n","    label_files = []\n","    for f in os.listdir(label_directory):\n","        g = os.path.join(label_directory, f)\n","        if os.path.isfile(g) and not f.lower().startswith('.') and f.lower().endswith('csv'):\n","            label_files.append(g)\n","    label_files = sorted(label_files)\n","\n","    prediction_files = []\n","    for f in os.listdir(prediction_directory):\n","        g = os.path.join(prediction_directory, f)\n","        if os.path.isfile(g) and not f.lower().startswith('.') and f.lower().endswith('csv'):\n","            prediction_files.append(g)\n","    prediction_files = sorted(prediction_files)\n","\n","    if len(label_files) != len(prediction_files):\n","        raise Exception('Numbers of label and prediction files must be the same.')\n","\n","    # Load labels and predictions.\n","    num_files            = len(label_files)\n","    cohort_labels        = []\n","    cohort_predictions   = []\n","    cohort_probabilities = []\n","\n","    for k in range(num_files):\n","        labels        = load_column(label_files[k], label_header, ',')\n","        predictions   = load_column(prediction_files[k], prediction_header, ',')\n","        probabilities = load_column(prediction_files[k], probability_header, ',')\n","\n","        # Check labels and predictions for errors.\n","        if not (len(labels) == len(predictions) and len(predictions) == len(probabilities)):\n","            raise Exception('Numbers of labels and predictions for a file must be the same.')\n","\n","        num_rows = len(labels)\n","\n","        for i in range(num_rows):\n","            if labels[i] not in (0, 1):\n","                raise Exception('Labels must satisfy label == 0 or label == 1.')\n","\n","            if predictions[i] not in (0, 1):\n","                raise Exception('Predictions must satisfy prediction == 0 or prediction == 1.')\n","\n","            if not 0 <= probabilities[i] <= 1:\n","                warnings.warn('Probabilities do not satisfy 0 <= probability <= 1.')\n","\n","        if 0 < np.sum(predictions) < num_rows:\n","            min_probability_positive = np.min(probabilities[predictions == 1])\n","            max_probability_negative = np.max(probabilities[predictions == 0])\n","\n","            if min_probability_positive <= max_probability_negative:\n","                warnings.warn('Predictions are inconsistent with probabilities, i.e., a positive prediction has a lower (or equal) probability than a negative prediction.')\n","\n","        # Record labels and predictions.\n","        cohort_labels.append(labels)\n","        cohort_predictions.append(predictions)\n","        cohort_probabilities.append(probabilities)\n","\n","    # Compute AUC, accuracy, and F-measure.\n","    labels        = np.concatenate(cohort_labels)\n","    predictions   = np.concatenate(cohort_predictions)\n","    probabilities = np.concatenate(cohort_probabilities)\n","\n","    auroc, auprc        = compute_auc(labels, probabilities)\n","    accuracy, f_measure = compute_accuracy_f_measure(labels, predictions)\n","\n","    # Compute utility.\n","    observed_utilities = np.zeros(num_files)\n","    best_utilities     = np.zeros(num_files)\n","    worst_utilities    = np.zeros(num_files)\n","    inaction_utilities = np.zeros(num_files)\n","\n","    for k in range(num_files):\n","        labels = cohort_labels[k]\n","        num_rows          = len(labels)\n","        observed_predictions = cohort_predictions[k]\n","        best_predictions     = np.zeros(num_rows)\n","        worst_predictions    = np.zeros(num_rows)\n","        inaction_predictions = np.zeros(num_rows)\n","\n","        if np.any(labels):\n","            t_sepsis = np.argmax(labels) - dt_optimal\n","            best_predictions[max(0, t_sepsis + dt_early) : min(t_sepsis + dt_late + 1, num_rows)] = 1\n","        worst_predictions = 1 - best_predictions\n","\n","        observed_utilities[k] = compute_prediction_utility(labels, observed_predictions, dt_early, dt_optimal, dt_late, max_u_tp, min_u_fn, u_fp, u_tn)\n","        best_utilities[k]     = compute_prediction_utility(labels, best_predictions, dt_early, dt_optimal, dt_late, max_u_tp, min_u_fn, u_fp, u_tn)\n","        worst_utilities[k]    = compute_prediction_utility(labels, worst_predictions, dt_early, dt_optimal, dt_late, max_u_tp, min_u_fn, u_fp, u_tn)\n","        inaction_utilities[k] = compute_prediction_utility(labels, inaction_predictions, dt_early, dt_optimal, dt_late, max_u_tp, min_u_fn, u_fp, u_tn)\n","\n","    unnormalized_observed_utility = np.sum(observed_utilities)\n","    unnormalized__utility     = np.sum(best_utilities)\n","    unnormalized_worst_utility    = np.sum(worst_utilities)\n","    unnormalized_inaction_utility = np.sum(inaction_utilities)\n","\n","    normalized_observed_utility = (unnormalized_observed_utility - unnormalized_inaction_utility) / (unnormalized__utility - unnormalized_inaction_utility)\n","\n","    return auroc, auprc, accuracy, f_measure, normalized_observed_utility\n","\n","# The load_column function loads a column from a table.\n","#\n","# Inputs:\n","#   'filename' is a string containing a filename.\n","#\n","#   'header' is a string containing a header.\n","#\n","# Outputs:\n","#   'column' is a vector containing a column from the file with the given\n","#   header.\n","#\n","# Example:\n","#   Omitted.\n","\n","def load_column(filename, header, delimiter):\n","    column = []\n","    with open(filename, 'r') as f:\n","        for i, l in enumerate(f):\n","            arrs = l.strip().split(delimiter)\n","            if i == 0:\n","                try:\n","                    j = arrs.index(header)\n","                except:\n","                    raise Exception('{} must contain column with header {} containing numerical entries.'.format(filename, header))\n","            else:\n","                if len(arrs[j]):\n","                    column.append(float(arrs[j]))\n","    return np.array(column)\n","\n","# The compute_auc function computes AUROC and AUPRC as well as other summary\n","# statistics (TP, FP, FN, TN, tpr_, TNR, PPV, NPV, etc.) that can be exposed\n","# from this function.\n","#\n","# Inputs:\n","#   'labels' is a binary vector, where labels[i] == 0 if the patient is not\n","#   labeled as septic at time i and labels[i] == 1 if the patient is labeled as\n","#   septic at time i.\n","#\n","#   'predictions' is a probability vector, where predictions[i] gives the\n","#   predicted probability that the patient is septic at time i.  Note that there\n","#   must be a prediction for every label, i.e, len(labels) ==\n","#   len(predictions).\n","#\n","# Outputs:\n","#   'auroc' is a scalar that gives the AUROC of the algorithm using its\n","#   predicted probabilities, where specificity is interpolated for intermediate\n","#   sensitivity values.\n","#\n","#   'auprc' is a scalar that gives the AUPRC of the algorithm using its\n","#   predicted probabilities, where precision is a piecewise constant function of\n","#   recall.\n","#\n","# Example:\n","#   In [1]: labels = [0, 0, 0, 0, 1, 1]\n","#   In [2]: predictions = [0.3, 0.4, 0.6, 0.7, 0.8, 0.8]\n","#   In [3]: auroc, auprc = compute_auc(labels, predictions)\n","#   In [4]: auroc\n","#   Out[4]: 1.0\n","#   In [5]: auprc\n","#   Out[5]: 1.0\n","\n","def compute_auc(labels, predictions, check_errors=True):\n","    # Check inputs for errors.\n","    if check_errors:\n","        if len(predictions) != len(labels):\n","            raise Exception('Numbers of predictions and labels must be the same.')\n","\n","        for label in labels:\n","            if not label in (0, 1):\n","                raise Exception('Labels must satisfy label == 0 or label == 1.')\n","\n","        for prediction in predictions:\n","            if not 0 <= prediction <= 1:\n","                warnings.warn('Predictions do not satisfy 0 <= prediction <= 1.')\n","\n","    # Find prediction thresholds.\n","    thresholds = np.unique(predictions)[::-1]\n","    if thresholds[0] != 1:\n","        thresholds = np.insert(thresholds, 0, 1)\n","    if thresholds[-1] == 0:\n","        thresholds = thresholds[:-1]\n","\n","    n = len(labels)\n","    m = len(thresholds)\n","\n","    # Populate contingency table across prediction thresholds.\n","    tp = np.zeros(m)\n","    fp = np.zeros(m)\n","    fn = np.zeros(m)\n","    tn = np.zeros(m)\n","\n","    # Find indices that sort the predicted probabilities from largest to\n","    # smallest.\n","    idx = np.argsort(predictions)[::-1]\n","\n","    i = 0\n","    for j in range(m):\n","        # Initialize contingency table for j-th prediction threshold.\n","        if j == 0:\n","            tp[j] = 0\n","            fp[j] = 0\n","            fn[j] = np.sum(labels)\n","            tn[j] = n - fn[j]\n","        else:\n","            tp[j] = tp[j - 1]\n","            fp[j] = fp[j - 1]\n","            fn[j] = fn[j - 1]\n","            tn[j] = tn[j - 1]\n","\n","        # Update contingency table for i-th largest predicted probability.\n","        while i < n and predictions[idx[i]] >= thresholds[j]:\n","            if labels[idx[i]]:\n","                tp[j] += 1\n","                fn[j] -= 1\n","            else:\n","                fp[j] += 1\n","                tn[j] -= 1\n","            i += 1\n","\n","    # Summarize contingency table.\n","    tpr_ = np.zeros(m)\n","    tnr = np.zeros(m)\n","    ppv = np.zeros(m)\n","    npv = np.zeros(m)\n","\n","    for j in range(m):\n","        if tp[j] + fn[j]:\n","            tpr_[j] = tp[j] / (tp[j] + fn[j])\n","        else:\n","            tpr_[j] = 1\n","        if fp[j] + tn[j]:\n","            tnr[j] = tn[j] / (fp[j] + tn[j])\n","        else:\n","            tnr[j] = 1\n","        if tp[j] + fp[j]:\n","            ppv[j] = tp[j] / (tp[j] + fp[j])\n","        else:\n","            ppv[j] = 1\n","        if fn[j] + tn[j]:\n","            npv[j] = tn[j] / (fn[j] + tn[j])\n","        else:\n","            npv[j] = 1\n","\n","    # Compute AUROC as the area under a piecewise linear function with tpr_ /\n","    # sensitivity (x-axis) and TNR / specificity (y-axis) and AUPRC as the area\n","    # under a piecewise constant with tpr_ / recall (x-axis) and PPV / precision\n","    # (y-axis).\n","    auroc = 0\n","    auprc = 0\n","    for j in range(m-1):\n","        auroc += 0.5 * (tpr_[j + 1] - tpr_[j]) * (tnr[j + 1] + tnr[j])\n","        auprc += (tpr_[j + 1] - tpr_[j]) * ppv[j + 1]\n","\n","    return auroc, auprc\n","\n","# The compute_accuracy_f_measure function computes the accuracy and F-measure\n","# for a patient.\n","#\n","# Inputs:\n","#   'labels' is a binary vector, where labels[i] == 0 if the patient is not\n","#   labeled as septic at time i and labels[i] == 1 if the patient is labeled as\n","#   septic at time i.\n","#\n","#   'predictions' is a binary vector, where predictions[i] == 0 if the patient\n","#   is not predicted to be septic at time i and predictions[i] == 1 if the\n","#   patient is predicted to be septic at time i.  Note that there must be a\n","#   prediction for every label, i.e, len(labels) == len(predictions).\n","#\n","# Output:\n","#   'accuracy' is a scalar that gives the accuracy of the predictions using its\n","#   binarized predictions.\n","#\n","#   'f_measure' is a scalar that gives the F-measure of the predictions using its\n","#   binarized predictions.\n","#\n","# Example:\n","#   In [1]: labels = [0, 0, 0, 0, 1, 1]\n","#   In [2]: predictions = [0, 0, 1, 1, 1, 1]\n","#   In [3]: accuracy, f_measure = compute_accuracy_f_measure(labels, predictions)\n","#   In [4]: accuracy\n","#   Out[4]: 0.666666666667\n","#   In [5]: f_measure\n","#   Out[5]: 0.666666666667\n","\n","def compute_accuracy_f_measure(labels, predictions, check_errors=True):\n","    # Check inputs for errors.\n","    if check_errors:\n","        if len(predictions) != len(labels):\n","            raise Exception('Numbers of predictions and labels must be the same.')\n","\n","        for label in labels:\n","            if not label in (0, 1):\n","                raise Exception('Labels must satisfy label == 0 or label == 1.')\n","\n","        for prediction in predictions:\n","            if not prediction in (0, 1):\n","                raise Exception('Predictions must satisfy prediction == 0 or prediction == 1.')\n","\n","    # Populate contingency table.\n","    n = len(labels)\n","    tp = 0\n","    fp = 0\n","    fn = 0\n","    tn = 0\n","\n","    for i in range(n):\n","        if labels[i] and predictions[i]:\n","            tp += 1\n","        elif not labels[i] and predictions[i]:\n","            fp += 1\n","        elif labels[i] and not predictions[i]:\n","            fn += 1\n","        elif not labels[i] and not predictions[i]:\n","            tn += 1\n","\n","    # Summarize contingency table.\n","    if tp + fp + fn + tn:\n","        accuracy = float(tp + tn) / float(tp + fp + fn + tn)\n","    else:\n","        accuracy = 1.0\n","\n","    if 2 * tp + fp + fn:\n","        f_measure = float(2 * tp) / float(2 * tp + fp + fn)\n","    else:\n","        f_measure = 1.0\n","\n","    return accuracy, f_measure\n","\n","# The compute_prediction_utility function computes the total time-dependent\n","# utility for a patient.\n","#\n","# Inputs:\n","#   'labels' is a binary vector, where labels[i] == 0 if the patient is not\n","#   labeled as septic at time i and labels[i] == 1 if the patient is labeled as\n","#   septic at time i.\n","#\n","#   'predictions' is a binary vector, where predictions[i] == 0 if the patient\n","#   is not predicted to be septic at time i and predictions[i] == 1 if the\n","#   patient is predicted to be septic at time i.  Note that there must be a\n","#   prediction for every label, i.e, len(labels) == len(predictions).\n","#\n","# Output:\n","#   'utility' is a scalar that gives the total time-dependent utility of the\n","#   algorithm using its binarized predictions.\n","#\n","# Example:\n","#   In [1]: labels = [0, 0, 0, 0, 1, 1]\n","#   In [2]: predictions = [0, 0, 1, 1, 1, 1]\n","#   In [3]: utility = compute_prediction_utility(labels, predictions)\n","#   In [4]: utility\n","#   Out[4]: 3.388888888888889\n","\n","def compute_prediction_utility(labels, predictions, dt_early=-12, dt_optimal=-6, dt_late=3.0, max_u_tp=1, min_u_fn=-2, u_fp=-0.05, u_tn=0, check_errors=True):\n","    # Check inputs for errors.\n","    if check_errors:\n","        if len(predictions) != len(labels):\n","            raise Exception('Numbers of predictions and labels must be the same.')\n","\n","        for label in labels:\n","            if not label in (0, 1):\n","                raise Exception('Labels must satisfy label == 0 or label == 1.')\n","\n","        for prediction in predictions:\n","            if not prediction in (0, 1):\n","                raise Exception('Predictions must satisfy prediction == 0 or prediction == 1.')\n","\n","        if dt_early >= dt_optimal:\n","            raise Exception('The earliest beneficial time for predictions must be before the optimal time.')\n","\n","        if dt_optimal >= dt_late:\n","            raise Exception('The optimal time for predictions must be before the latest beneficial time.')\n","\n","    # Does the patient eventually have sepsis?\n","    if np.any(labels):\n","        is_septic = True\n","        t_sepsis = np.argmax(labels) - dt_optimal\n","    else:\n","        is_septic = False\n","        t_sepsis = float('inf')\n","\n","    n = len(labels)\n","\n","    # Define slopes and intercept points for utility functions of the form\n","    # u = m * t + b.\n","    m_1 = float(max_u_tp) / float(dt_optimal - dt_early)\n","    b_1 = -m_1 * dt_early\n","    m_2 = float(-max_u_tp) / float(dt_late - dt_optimal)\n","    b_2 = -m_2 * dt_late\n","    m_3 = float(min_u_fn) / float(dt_late - dt_optimal)\n","    b_3 = -m_3 * dt_optimal\n","\n","    # Compare predicted and true conditions.\n","    u = np.zeros(n)\n","    for t in range(n):\n","        if t <= t_sepsis + dt_late:\n","            # TP\n","            if is_septic and predictions[t]:\n","                if t <= t_sepsis + dt_optimal:\n","                    u[t] = max(m_1 * (t - t_sepsis) + b_1, u_fp)\n","                elif t <= t_sepsis + dt_late:\n","                    u[t] = m_2 * (t - t_sepsis) + b_2\n","            # FP\n","            elif not is_septic and predictions[t]:\n","                u[t] = u_fp\n","            # FN\n","            elif is_septic and not predictions[t]:\n","                if t <= t_sepsis + dt_optimal:\n","                    u[t] = 0\n","                elif t <= t_sepsis + dt_late:\n","                    u[t] = m_3 * (t - t_sepsis) + b_3\n","            # TN\n","            elif not is_septic and not predictions[t]:\n","                u[t] = u_tn\n","\n","    # Find total utility for patient.\n","    return np.sum(u)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Baseline Data without Feature Selection"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["!mkdir -p ./prediction\n","!mkdir -p ./label"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# load test data\n","test_set = np.load('../data/data_both/test_set.npy')\n","test_data_path = '../data/data_both/test_baseline/' \n","\n","# pathes\n","prediction_directory = './prediction/'\n","label_directory = './label/'\n","model_path = './trained_models/BDWOFS/' \n","\n","predict(test_set, test_data_path, prediction_directory, label_directory, model_path, 0.5, X_feature_baseline)\n","\n","auroc, auprc, accuracy, f_measure, utility = evaluate_sepsis_score(label_directory, prediction_directory)\n","output_string = 'AUROC|AUPRC|Accuracy|F-measure|Utility\\n{}|{}|{}|{}|{}'.format(\n","                auroc, auprc, accuracy, f_measure, utility)\n","print(output_string)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Results:\n","\n","AUROC|AUPRC|Accuracy|F-measure|Utility\n","\n","0.5213224697648841|0.10036421964552332|0.5518996912607901|0.1496520553841739|0.361013145579852"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Baseline Data with Feature Selection"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["!rm -r -f ./prediction\n","!rm -r -f ./label\n","!mkdir -p ./prediction\n","!mkdir -p ./label"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# load test data\n","test_set = np.load('../data/data_both/test_set.npy')\n","test_data_path = '../data/data_both/test_baseline/' \n","\n","# pathes\n","prediction_directory = './prediction/'\n","label_directory = './label/'\n","model_path = './trained_models/BDWFS/' \n","\n","predict(test_set, test_data_path, prediction_directory, label_directory, model_path, 0.5, X_feature_baseline_fs)\n","\n","auroc, auprc, accuracy, f_measure, utility = evaluate_sepsis_score(label_directory, prediction_directory)\n","output_string = 'AUROC|AUPRC|Accuracy|F-measure|Utility\\n{}|{}|{}|{}|{}'.format(\n","                auroc, auprc, accuracy, f_measure, utility)\n","print(output_string)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Results:\n","\n","AUROC|AUPRC|Accuracy|F-measure|Utility\n","\n","0.5680442055030079|0.11604327516848185|0.5609854451515343|0.16759055720156743|0.41790978899004516"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Engineered Data without Feature Selection"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["!rm -r -f ./prediction\n","!rm -r -f ./label\n","!mkdir -p ./prediction\n","!mkdir -p ./label"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# load test data\n","test_set = np.load('../data/data_both/test_set.npy')\n","test_data_path = '../data/data_both/test_engineered/' \n","\n","# pathes\n","prediction_directory = './prediction/'\n","label_directory = './label/'\n","model_path = './trained_models/EDWOFS/' \n","\n","predict(test_set, test_data_path, prediction_directory, label_directory, model_path, 0.5, X_feature_engineered)\n","\n","auroc, auprc, accuracy, f_measure, utility = evaluate_sepsis_score(label_directory, prediction_directory)\n","output_string = 'AUROC|AUPRC|Accuracy|F-measure|Utility\\n{}|{}|{}|{}|{}'.format(\n","                auroc, auprc, accuracy, f_measure, utility)\n","print(output_string)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Results:\n","\n","AUROC|AUPRC|Accuracy|F-measure|Utility \n","\n","0.7557546797659839|0.3654222701215125|0.5709281078696995|0.22267881195351916|0.6322508083042628\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Engineered Data with Feature Selection"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["!rm -r -f ./prediction\n","!rm -r -f ./label\n","!mkdir -p ./prediction\n","!mkdir -p ./label"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1446/1446 [00:27<00:00, 52.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["AUROC|AUPRC|Accuracy|F-measure|Utility\n","0.7448881931154562|0.3536970550301417|0.5667695797366266|0.21928011808788464|0.6215216327746108\n"]}],"source":["# load test data\n","test_set = np.load('../data/data_both/test_set.npy')\n","test_data_path = '../data/data_both/test_engineered/' \n","\n","# pathes\n","prediction_directory = './prediction/'\n","label_directory = './label/'\n","model_path = './trained_models/EDWFS/' \n","\n","predict(test_set, test_data_path, prediction_directory, label_directory, model_path, 0.5, X_feature_engineered_fs)\n","\n","auroc, auprc, accuracy, f_measure, utility = evaluate_sepsis_score(label_directory, prediction_directory)\n","output_string = 'AUROC|AUPRC|Accuracy|F-measure|Utility\\n{}|{}|{}|{}|{}'.format(\n","                auroc, auprc, accuracy, f_measure, utility)\n","print(output_string)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Results:\n","\n","AUROC|AUPRC|Accuracy|F-measure|Utility\n","\n","0.7448881931154562|0.3536970550301417|0.5667695797366266|0.21928011808788464|0.6215216327746108"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Test Real Neonatal Data"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["neonate_sepsis = np.load('../../models_neoantes/data/all_sepsis.npy')\n","neonate_nonsepsis = np.load('../../models_neoantes/data/all_nonsepsis.npy')\n","neonate_nonsepsis_balanced = np.random.choice(neonate_nonsepsis, len(neonate_sepsis), replace=False)\n","test_set_balanced = np.concatenate((neonate_sepsis, neonate_nonsepsis_balanced))\n","np.save('../../models_neoantes/data/test_set_balanced.npy', test_set_balanced)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### BDWOFS"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["!rm -r -f ./prediction\n","!rm -r -f ./label\n","!mkdir -p ./prediction\n","!mkdir -p ./label"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 226/226 [00:05<00:00, 43.23it/s]\n"]},{"name":"stdout","output_type":"stream","text":["AUROC|AUPRC|Accuracy|F-measure|Utility\n","0.5387213805423651|0.05615803353392489|0.513461266443491|0.07560691570366389|0.18441979309485226\n"]}],"source":["# load test data\n","test_set = np.load('../../models_neoantes/data/test_set_balanced.npy')\n","test_data_path = '../../datasets/MIMICIII/neonates/baseline_all/' \n","\n","# pathes\n","prediction_directory = './prediction/'\n","label_directory = './label/'\n","model_path = './trained_models/BDWOFS/' \n","\n","predict(test_set, test_data_path, prediction_directory, label_directory, model_path, 0.5, X_feature_baseline)\n","\n","auroc, auprc, accuracy, f_measure, utility = evaluate_sepsis_score(label_directory, prediction_directory)\n","output_string = 'AUROC|AUPRC|Accuracy|F-measure|Utility\\n{}|{}|{}|{}|{}'.format(\n","                auroc, auprc, accuracy, f_measure, utility)\n","print(output_string)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### BDWFS"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["!rm -r -f ./prediction\n","!rm -r -f ./label\n","!mkdir -p ./prediction\n","!mkdir -p ./label"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 226/226 [00:04<00:00, 47.76it/s]\n"]},{"name":"stdout","output_type":"stream","text":["AUROC|AUPRC|Accuracy|F-measure|Utility\n","0.5319552082091128|0.0541009365500336|0.5130369182894055|0.07471779251030282|0.17702438821720878\n"]}],"source":["# load test data\n","test_set = np.load('../../models_neoantes/data/test_set_balanced.npy')\n","test_data_path = '../../datasets/MIMICIII/neonates/baseline_all/' \n","\n","# pathes\n","prediction_directory = './prediction/'\n","label_directory = './label/'\n","model_path = './trained_models/BDWFS/' \n","\n","predict(test_set, test_data_path, prediction_directory, label_directory, model_path, 0.5, X_feature_baseline_fs)\n","\n","auroc, auprc, accuracy, f_measure, utility = evaluate_sepsis_score(label_directory, prediction_directory)\n","output_string = 'AUROC|AUPRC|Accuracy|F-measure|Utility\\n{}|{}|{}|{}|{}'.format(\n","                auroc, auprc, accuracy, f_measure, utility)\n","print(output_string)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### EDWOFS"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["!rm -r -f ./prediction\n","!rm -r -f ./label\n","!mkdir -p ./prediction\n","!mkdir -p ./label"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 226/226 [00:06<00:00, 33.69it/s]\n"]},{"name":"stdout","output_type":"stream","text":["AUROC|AUPRC|Accuracy|F-measure|Utility\n","0.7838814788617027|0.2391587047850281|0.5659389881654014|0.1254037621128634|0.48729901533092357\n"]}],"source":["# load test data\n","test_set = np.load('../../models_neoantes/data/test_set_balanced.npy')\n","test_data_path = '../../datasets/MIMICIII/neonates/engineered_all/' \n","\n","# pathes\n","prediction_directory = './prediction/'\n","label_directory = './label/'\n","model_path = './trained_models/EDWOFS/' \n","\n","predict(test_set, test_data_path, prediction_directory, label_directory, model_path, 0.5, X_feature_engineered)\n","\n","auroc, auprc, accuracy, f_measure, utility = evaluate_sepsis_score(label_directory, prediction_directory)\n","output_string = 'AUROC|AUPRC|Accuracy|F-measure|Utility\\n{}|{}|{}|{}|{}'.format(\n","                auroc, auprc, accuracy, f_measure, utility)\n","print(output_string)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### EDWFS"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["!rm -r -f ./prediction\n","!rm -r -f ./label\n","!mkdir -p ./prediction\n","!mkdir -p ./label"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 226/226 [00:05<00:00, 39.79it/s]\n"]},{"name":"stdout","output_type":"stream","text":["AUROC|AUPRC|Accuracy|F-measure|Utility\n","0.7707348774704764|0.2199808045974155|0.5685322268848131|0.12606245821793524|0.48459013669034856\n"]}],"source":["# load test data\n","test_set = np.load('../../models_neoantes/data/test_set_balanced.npy')\n","test_data_path = '../../datasets/MIMICIII/neonates/engineered_all/' \n","\n","# pathes\n","prediction_directory = './prediction/'\n","label_directory = './label/'\n","model_path = './trained_models/EDWFS/' \n","\n","predict(test_set, test_data_path, prediction_directory, label_directory, model_path, 0.5, X_feature_engineered_fs)\n","\n","auroc, auprc, accuracy, f_measure, utility = evaluate_sepsis_score(label_directory, prediction_directory)\n","output_string = 'AUROC|AUPRC|Accuracy|F-measure|Utility\\n{}|{}|{}|{}|{}'.format(\n","                auroc, auprc, accuracy, f_measure, utility)\n","print(output_string)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Test Artificial Neonatal Data\n","### BDWOFS"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["!rm -r -f ./prediction\n","!rm -r -f ./label\n","!mkdir -p ./prediction\n","!mkdir -p ./label"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 226/226 [00:06<00:00, 36.64it/s]\n"]},{"name":"stdout","output_type":"stream","text":["AUROC|AUPRC|Accuracy|F-measure|Utility\n","0.46690971473585635|0.04205330411922846|0.5060211474446837|0.06625335430739336|0.10099713324192952\n"]}],"source":["# load test data\n","test_set = np.load('../../artificial_neonatal_data/data/balanced_226/test_set_balanced.npy')\n","test_data_path = '../../artificial_neonatal_data/data/balanced_226/baseline_all/' \n","\n","# pathes\n","prediction_directory = './prediction/'\n","label_directory = './label/'\n","model_path = './trained_models/BDWOFS/' \n","\n","predict(test_set, test_data_path, prediction_directory, label_directory, model_path, 0.5, X_feature_baseline)\n","\n","auroc, auprc, accuracy, f_measure, utility = evaluate_sepsis_score(label_directory, prediction_directory)\n","output_string = 'AUROC|AUPRC|Accuracy|F-measure|Utility\\n{}|{}|{}|{}|{}'.format(\n","                auroc, auprc, accuracy, f_measure, utility)\n","print(output_string)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### BDWFS"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!rm -r -f ./prediction\n","!rm -r -f ./label\n","!mkdir -p ./prediction\n","!mkdir -p ./label"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 226/226 [00:05<00:00, 40.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["AUROC|AUPRC|Accuracy|F-measure|Utility\n","0.4654106997761587|0.04185025794738932|0.5052868611709418|0.06564349112426035|0.09874942872574685\n"]}],"source":["# load test data\n","test_set = np.load('../../artificial_neonatal_data/data/balanced_226/test_set_balanced.npy')\n","test_data_path = '../../artificial_neonatal_data/data/balanced_226/baseline_all/' \n","\n","# pathes\n","prediction_directory = './prediction/'\n","label_directory = './label/'\n","model_path = './trained_models/BDWFS/' \n","\n","predict(test_set, test_data_path, prediction_directory, label_directory, model_path, 0.5, X_feature_baseline_fs)\n","\n","auroc, auprc, accuracy, f_measure, utility = evaluate_sepsis_score(label_directory, prediction_directory)\n","output_string = 'AUROC|AUPRC|Accuracy|F-measure|Utility\\n{}|{}|{}|{}|{}'.format(\n","                auroc, auprc, accuracy, f_measure, utility)\n","print(output_string)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### EDWOFS"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["!rm -r -f ./prediction\n","!rm -r -f ./label\n","!mkdir -p ./prediction\n","!mkdir -p ./label"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 226/226 [00:06<00:00, 33.27it/s]\n"]},{"name":"stdout","output_type":"stream","text":["AUROC|AUPRC|Accuracy|F-measure|Utility\n","0.8555088059403332|0.2790463515870136|0.5618269042490699|0.1384156319183752|0.572209065603058\n"]}],"source":["# load test data\n","test_set = np.load('../../artificial_neonatal_data/data/balanced_226/test_set_balanced.npy')\n","test_data_path = '../../artificial_neonatal_data/data/balanced_226/engineered_all/' \n","\n","# pathes\n","prediction_directory = './prediction/'\n","label_directory = './label/'\n","model_path = './trained_models/EDWOFS/' \n","\n","predict(test_set, test_data_path, prediction_directory, label_directory, model_path, 0.5, X_feature_engineered)\n","\n","auroc, auprc, accuracy, f_measure, utility = evaluate_sepsis_score(label_directory, prediction_directory)\n","output_string = 'AUROC|AUPRC|Accuracy|F-measure|Utility\\n{}|{}|{}|{}|{}'.format(\n","                auroc, auprc, accuracy, f_measure, utility)\n","print(output_string)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### EDWFS"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!rm -r -f ./prediction\n","!rm -r -f ./label\n","!mkdir -p ./prediction\n","!mkdir -p ./label"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 226/226 [00:05<00:00, 42.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["AUROC|AUPRC|Accuracy|F-measure|Utility\n","0.8404158420979196|0.26552646601277174|0.5564421382416291|0.1351531927078362|0.5542066558643899\n"]}],"source":["# load test data\n","test_set = np.load('../../artificial_neonatal_data/data/balanced_226/test_set_balanced.npy')\n","test_data_path = '../../artificial_neonatal_data/data/balanced_226/engineered_all/' \n","\n","# pathes\n","prediction_directory = './prediction/'\n","label_directory = './label/'\n","model_path = './trained_models/EDWFS/' \n","\n","predict(test_set, test_data_path, prediction_directory, label_directory, model_path, 0.5, X_feature_engineered_fs)\n","\n","auroc, auprc, accuracy, f_measure, utility = evaluate_sepsis_score(label_directory, prediction_directory)\n","output_string = 'AUROC|AUPRC|Accuracy|F-measure|Utility\\n{}|{}|{}|{}|{}'.format(\n","                auroc, auprc, accuracy, f_measure, utility)\n","print(output_string)"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"DL_Environment","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.13"},"vscode":{"interpreter":{"hash":"fd901a71f1e124788c289e11a286c3218d50d6e5c83a9d223b7671fe76e12162"}}},"nbformat":4,"nbformat_minor":0}
